{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d07b8d4a",
   "metadata": {
    "papermill": {
     "duration": 0.007869,
     "end_time": "2024-05-03T23:39:40.231135",
     "exception": false,
     "start_time": "2024-05-03T23:39:40.223266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Sampling large Datasets\n",
    "In data processing, a great deal of computing involves analysing large amounts of text mixed with numerical data.  This is what Spark is particularly suited for. Sampling is an essential pre-processing for machine leanring for proof of concept\n",
    "\n",
    "## Recbole dataset\n",
    "Recbole is a powerful recommendation system traning and evaluation platform. It has many built-in datasets(https://recbole.io/dataset_list.html), some of which is too large to process on a single computer. I will use spark to preprocess it to shrink its size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a766095",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:39:40.248308Z",
     "iopub.status.busy": "2024-05-03T23:39:40.247886Z",
     "iopub.status.idle": "2024-05-03T23:40:33.853828Z",
     "shell.execute_reply": "2024-05-03T23:40:33.852725Z"
    },
    "papermill": {
     "duration": 53.617629,
     "end_time": "2024-05-03T23:40:33.856628",
     "exception": false,
     "start_time": "2024-05-03T23:39:40.238999",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\r\n",
      "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: py4j==0.10.9.7 in /opt/conda/lib/python3.10/site-packages (from pyspark) (0.10.9.7)\r\n",
      "Building wheels for collected packages: pyspark\r\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l-\b \b\\\b \b|\b \bdone\r\n",
      "\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488493 sha256=5c414f85c4eb88f571626769d4fee3db60653989828d045e0930b53ef5cce719\r\n",
      "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\r\n",
      "Successfully built pyspark\r\n",
      "Installing collected packages: pyspark\r\n",
      "Successfully installed pyspark-3.5.1\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6de415e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:40:33.893782Z",
     "iopub.status.busy": "2024-05-03T23:40:33.893340Z",
     "iopub.status.idle": "2024-05-03T23:40:52.960406Z",
     "shell.execute_reply": "2024-05-03T23:40:52.958152Z"
    },
    "papermill": {
     "duration": 19.089798,
     "end_time": "2024-05-03T23:40:52.963847",
     "exception": false,
     "start_time": "2024-05-03T23:40:33.874049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rm: cannot remove 'url.yaml': No such file or directory\r\n",
      "--2024-05-03 23:40:36--  https://raw.githubusercontent.com/RUCAIBox/RecBole/master/recbole/properties/dataset/url.yaml\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 16548 (16K) [text/plain]\r\n",
      "Saving to: 'url.yaml'\r\n",
      "\r\n",
      "url.yaml            100%[===================>]  16.16K  --.-KB/s    in 0.001s  \r\n",
      "\r\n",
      "2024-05-03 23:40:36 (27.2 MB/s) - 'url.yaml' saved [16548/16548]\r\n",
      "\r\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (6.0.1)\r\n",
      "adult : https://recbole.s3-accelerate.amazonaws.com/ProcessedDatasets/Adult/adult.zip\n",
      "alibaba-ifashion : https://recbole.s3-accelerate.amazonaws.com/ProcessedDatasets/Alibaba-iFashion/Alibaba-iFashion.zip\n",
      "aliec : https://recbole.s3-accelerate.amazonaws.com/ProcessedDatasets/AliEC/AliEC.zip\n",
      "amazon-apps-for-android : https://recbole.s3-accelerate.amazonaws.com/ProcessedDatasets/Amazon_ratings/Amazon_Apps_for_Android.zip\n",
      "amazon-automotive : https://recbole.s3-accelerate.amazonaws.com/ProcessedDatasets/Amazon_ratings/Amazon_Automotive.zip\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!rm url.yaml\n",
    "!wget https://raw.githubusercontent.com/RUCAIBox/RecBole/master/recbole/properties/dataset/url.yaml\n",
    "!pip install pyyaml\n",
    "\n",
    "import yaml\n",
    "\n",
    "# Specify the path to the YAML file\n",
    "file_path = \"url.yaml\"\n",
    "\n",
    "# Open the file and load the YAML contents\n",
    "with open(file_path, \"r\") as file:\n",
    "    dataset_urls = yaml.safe_load(file)\n",
    "   \n",
    "# only print the first 5 lines\n",
    "for key in list(dataset_urls.keys())[:5]:\n",
    "    print(key, \":\", dataset_urls[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1459f7a7",
   "metadata": {
    "papermill": {
     "duration": 0.022255,
     "end_time": "2024-05-03T23:40:53.008285",
     "exception": false,
     "start_time": "2024-05-03T23:40:52.986030",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Set the datasets to donwload and process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30dfd115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:40:53.049529Z",
     "iopub.status.busy": "2024-05-03T23:40:53.049063Z",
     "iopub.status.idle": "2024-05-03T23:40:53.062604Z",
     "shell.execute_reply": "2024-05-03T23:40:53.061481Z"
    },
    "papermill": {
     "duration": 0.037451,
     "end_time": "2024-05-03T23:40:53.064999",
     "exception": false,
     "start_time": "2024-05-03T23:40:53.027548",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "datasets_to_download = ['amazon-digital-music', 'amazon-video-games']\n",
    "# datasets_to_download = ['amazon-cds-vinyl']\n",
    "import os\n",
    "# Path to the folder where the zip file will be extracted\n",
    "input_folder_path = \"input\"\n",
    "\n",
    "# Create input folder if it doesn't exist\n",
    "if not os.path.exists(input_folder_path):\n",
    "    os.makedirs(input_folder_path)\n",
    "    \n",
    "# Path to the folder where processed file will be saved\n",
    "output_folder_path = \"output\"\n",
    "\n",
    "# Create out folder if it doesn't exist\n",
    "if not os.path.exists(output_folder_path):\n",
    "    os.makedirs(output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c916a9c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:40:53.107283Z",
     "iopub.status.busy": "2024-05-03T23:40:53.106198Z",
     "iopub.status.idle": "2024-05-03T23:41:12.316350Z",
     "shell.execute_reply": "2024-05-03T23:41:12.315277Z"
    },
    "papermill": {
     "duration": 19.235504,
     "end_time": "2024-05-03T23:41:12.319401",
     "exception": false,
     "start_time": "2024-05-03T23:40:53.083897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (2.31.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests) (2024.2.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "\n",
    "def download_upzip(url, dataset_name):\n",
    "    # Download the zip file\n",
    "    response = requests.get(url)\n",
    "    zip_file = zipfile.ZipFile(io.BytesIO(response.content))\n",
    "\n",
    "    # Extract the zip file to the specified folder of dataset_name\n",
    "    folder_path = os.path.join(input_folder_path, dataset_name)\n",
    "    if not os.path.exists(folder_path):\n",
    "        os.makedirs(folder_path)\n",
    "    zip_file.extractall(folder_path)\n",
    "\n",
    "    #TODO: if extracted file is a directory, move all files to the parent directory\n",
    "    # for root, dirs, files in os.walk(folder_path):\n",
    "    #     for file in files:\n",
    "    #         os.rename(os.path.join(root, file), os.path.join(folder_path, file))\n",
    "    #     for dir in dirs:\n",
    "    #         os.rmdir(os.path.join(root, dir))\n",
    "\n",
    "    # Close the zip file\n",
    "    zip_file.close()\n",
    "\n",
    "#  download all dataset from datasets_to_download\n",
    "for dataset in datasets_to_download:\n",
    "    download_upzip(dataset_urls[dataset], dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "214666ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:41:12.357806Z",
     "iopub.status.busy": "2024-05-03T23:41:12.357348Z",
     "iopub.status.idle": "2024-05-03T23:41:18.658590Z",
     "shell.execute_reply": "2024-05-03T23:41:18.657174Z"
    },
    "papermill": {
     "duration": 6.324929,
     "end_time": "2024-05-03T23:41:18.662511",
     "exception": false,
     "start_time": "2024-05-03T23:41:12.337582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/05/03 23:41:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Amazon Sampling\").getOrCreate()\n",
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "207b649b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:41:18.702428Z",
     "iopub.status.busy": "2024-05-03T23:41:18.701086Z",
     "iopub.status.idle": "2024-05-03T23:41:47.766422Z",
     "shell.execute_reply": "2024-05-03T23:41:47.765264Z"
    },
    "papermill": {
     "duration": 29.08956,
     "end_time": "2024-05-03T23:41:47.770509",
     "exception": false,
     "start_time": "2024-05-03T23:41:18.680949",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: amazon-digital-music, File: Amazon_Digital_Music.item\n",
      "+-------------+--------------------+-----------+----------------+----------------+--------------------+-----------+\n",
      "|item_id:token|         title:token|price:float|sales_type:token|sales_rank:float|categories:token_seq|brand:token|\n",
      "+-------------+--------------------+-----------+----------------+----------------+--------------------+-----------+\n",
      "|   5555991584|     Memory of Trees|       9.49|           Music|        939190.0|'CDs & Vinyl', 'P...|       NULL|\n",
      "|   6308051551|Don't Drink His B...|       8.91|            NULL|            NULL|'Digital Music', ...|       NULL|\n",
      "|   7901622466|             On Fire|      11.33|           Music|         58799.0|'CDs & Vinyl', 'C...|       NULL|\n",
      "|   B0000000ZW|      Changing Faces|      23.64|           Music|         68784.0|'CDs & Vinyl', 'P...|       NULL|\n",
      "|   B00000016W|          Pet Sounds|       9.49|           Music|         77205.0|'CDs & Vinyl', 'C...|       NULL|\n",
      "+-------------+--------------------+-----------+----------------+----------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "num of Amazon_Digital_Music.item: 279899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of disintict item_id:token: 279899\n",
      "Number of non-null values in each column:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+-----------+----------------+----------------+--------------------+-----------+\n",
      "|item_id:token|title:token|price:float|sales_type:token|sales_rank:float|categories:token_seq|brand:token|\n",
      "+-------------+-----------+-----------+----------------+----------------+--------------------+-----------+\n",
      "|       279899|       7321|      86174|            9531|            9531|              279899|        554|\n",
      "+-------------+-----------+-----------+----------------+----------------+--------------------+-----------+\n",
      "\n",
      "Dataset: amazon-digital-music, File: Amazon_Digital_Music.inter\n",
      "+--------------+-------------+------------+---------------+\n",
      "| user_id:token|item_id:token|rating:float|timestamp:float|\n",
      "+--------------+-------------+------------+---------------+\n",
      "|A2EFCYXHNK06IS|   5555991584|         5.0|      978480000|\n",
      "|A1WR23ER5HMAA9|   5555991584|         5.0|      953424000|\n",
      "|A2IR4Q0GPAFJKW|   5555991584|         4.0|     1393545600|\n",
      "|A2V0KUVAB9HSYO|   5555991584|         4.0|      966124800|\n",
      "|A1J0GL9HCA7ELW|   5555991584|         5.0|     1007683200|\n",
      "+--------------+-------------+------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "num of Amazon_Digital_Music.inter: 836006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of disintict user_id:token: 478235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of disintict item_id:token: 266414\n",
      "Number of non-null values in each column:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+------------+---------------+\n",
      "|user_id:token|item_id:token|rating:float|timestamp:float|\n",
      "+-------------+-------------+------------+---------------+\n",
      "|       836006|       836006|      836006|         836006|\n",
      "+-------------+-------------+------------+---------------+\n",
      "\n",
      "Dataset: amazon-video-games, File: Amazon_Video_Games.inter\n",
      "+--------------+-------------+------------+---------------+\n",
      "| user_id:token|item_id:token|rating:float|timestamp:float|\n",
      "+--------------+-------------+------------+---------------+\n",
      "| AB9S9279OZ3QO|   0078764343|         5.0|     1373155200|\n",
      "|A24SSUT5CSW8BH|   0078764343|         5.0|     1377302400|\n",
      "| AK3V0HEBJMQ7J|   0078764343|         4.0|     1372896000|\n",
      "|A10BECPH7W8HM7|   043933702X|         5.0|     1404950400|\n",
      "|A2PRV9OULX1TWP|   043933702X|         5.0|     1386115200|\n",
      "+--------------+-------------+------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of Amazon_Video_Games.inter: 1324753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of disintict user_id:token: 826767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of disintict item_id:token: 50210\n",
      "Number of non-null values in each column:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------+------------+---------------+\n",
      "|user_id:token|item_id:token|rating:float|timestamp:float|\n",
      "+-------------+-------------+------------+---------------+\n",
      "|      1324753|      1324753|     1324753|        1324753|\n",
      "+-------------+-------------+------------+---------------+\n",
      "\n",
      "Dataset: amazon-video-games, File: Amazon_Video_Games.item\n",
      "+-------------+-----------+----------------+----------------+--------------------+-----------+-----------+\n",
      "|item_id:token|price:float|sales_type:token|sales_rank:float|categories:token_seq|title:token|brand:token|\n",
      "+-------------+-----------+----------------+----------------+--------------------+-----------+-----------+\n",
      "|   0078764343|      37.98|     Video Games|         28655.0|'Games', 'Video G...|       NULL|       NULL|\n",
      "|   043933702X|       23.5|     Video Games|         44080.0|'Games', 'Video G...|       NULL|       NULL|\n",
      "|   0439339987|       8.95|     Video Games|         49836.0|'Games', 'Video G...|       NULL|       NULL|\n",
      "|   0439342260|       NULL|     Video Games|         49156.0|'Games', 'Video G...|       NULL|       NULL|\n",
      "|   0439339960|       NULL|     Video Games|         52262.0|'Games', 'Video G...|       NULL|       NULL|\n",
      "+-------------+-----------+----------------+----------------+--------------------+-----------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "num of Amazon_Video_Games.item: 50953\n",
      "Number of disintict item_id:token: 50953\n",
      "Number of non-null values in each column:\n",
      "+-------------+-----------+----------------+----------------+--------------------+-----------+-----------+\n",
      "|item_id:token|price:float|sales_type:token|sales_rank:float|categories:token_seq|title:token|brand:token|\n",
      "+-------------+-----------+----------------+----------------+--------------------+-----------+-----------+\n",
      "|        50953|      43905|           48627|           48627|               50953|       2265|        747|\n",
      "+-------------+-----------+----------------+----------------+--------------------+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "\n",
    "# read from file into dataframe\n",
    "dfs = {}\n",
    "for dataset in datasets_to_download:\n",
    "    dataset_path = os.path.join(input_folder_path, dataset)\n",
    "    dfs[dataset] = {}\n",
    "    for file in os.listdir(dataset_path):\n",
    "        file_path = os.path.join(dataset_path, file)\n",
    "        df = spark.read.option(\"delimiter\",'\\t').option(\"header\", True).csv(file_path)\n",
    "        dfs[dataset][file] = df\n",
    "        print(f\"Dataset: {dataset}, File: {file}\")\n",
    "        df.show(5)\n",
    "        \n",
    "        print(f'num of {file}:',df.count())\n",
    "\n",
    "        # check the uniqueness of key, we assume key name is ending with _id bofore :token i.e. item_id:token\n",
    "        # find the header ending with _id:token\n",
    "        key_columns = [col for col in df.columns if col.endswith('_id:token')]\n",
    "        for key_column in key_columns:\n",
    "            print(f\"Number of disintict {key_column}:\", df.select(key_column).distinct().count())\n",
    "            \n",
    "\n",
    "        # check the completeness of each column\n",
    "        print(\"Number of non-null values in each column:\")\n",
    "        df.select([count(when(col(c).isNotNull() , c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56205478",
   "metadata": {
    "papermill": {
     "duration": 0.022333,
     "end_time": "2024-05-03T23:41:47.823260",
     "exception": false,
     "start_time": "2024-05-03T23:41:47.800927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "301a48d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:41:47.869977Z",
     "iopub.status.busy": "2024-05-03T23:41:47.869306Z",
     "iopub.status.idle": "2024-05-03T23:41:47.875474Z",
     "shell.execute_reply": "2024-05-03T23:41:47.874307Z"
    },
    "papermill": {
     "duration": 0.032094,
     "end_time": "2024-05-03T23:41:47.877792",
     "exception": false,
     "start_time": "2024-05-03T23:41:47.845698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "inter_map = {}\n",
    "# analyze the sparse of the dataset\n",
    "for dataset in datasets_to_download:\n",
    "    dataset_path = os.path.join(input_folder_path, dataset)\n",
    "    for file in os.listdir(dataset_path):\n",
    "        if file.endswith('.inter'):\n",
    "            inter_map[dataset] = file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95739640",
   "metadata": {
    "papermill": {
     "duration": 0.022834,
     "end_time": "2024-05-03T23:41:47.923109",
     "exception": false,
     "start_time": "2024-05-03T23:41:47.900275",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### filter out inactive user/items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34388018",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:41:47.969560Z",
     "iopub.status.busy": "2024-05-03T23:41:47.969098Z",
     "iopub.status.idle": "2024-05-03T23:42:26.564683Z",
     "shell.execute_reply": "2024-05-03T23:42:26.563217Z"
    },
    "papermill": {
     "duration": 38.622694,
     "end_time": "2024-05-03T23:42:26.567983",
     "exception": false,
     "start_time": "2024-05-03T23:41:47.945289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "Dataset: amazon-digital-music\n",
      "num of iteractions: 836006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of user_id: 478235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of item_id: 266414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+------------+---------------+----------+----------+\n",
      "|item_id:token| user_id:token|rating:float|timestamp:float|count_user|count_item|\n",
      "+-------------+--------------+------------+---------------+----------+----------+\n",
      "|   B0000001Q8|A3U3UXV7VQ6GGD|         5.0|     1222387200|         6|         3|\n",
      "|   B0000001Q8|A247RM73M8B176|         4.0|     1108166400|         1|         3|\n",
      "|   B0000001Q8|A1X67QWGL8QVX9|         5.0|     1168300800|        15|         3|\n",
      "|   B0000001SH|A1LIOQNKOYCWBN|         5.0|     1370995200|         1|         5|\n",
      "|   B0000001SH|A29PW3RBYPME61|         5.0|     1363564800|         1|         5|\n",
      "+-------------+--------------+------------+---------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered num of iteractions: 65344\n",
      "-----------------------------------\n",
      "Dataset: amazon-video-games\n",
      "num of iteractions: 1324753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of user_id: 826767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of item_id: 50210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+------------+---------------+----------+----------+\n",
      "|item_id:token| user_id:token|rating:float|timestamp:float|count_user|count_item|\n",
      "+-------------+--------------+------------+---------------+----------+----------+\n",
      "|   B00014WNE6|A100UZ3LRLU135|         4.0|     1120780800|         1|        36|\n",
      "|   B002I0HBZW|A100VTYZQ17B4I|         5.0|     1305590400|         1|       413|\n",
      "|   B000TKB28K|A101SY98T3JQMU|         5.0|     1231632000|         1|        47|\n",
      "|   B00BMFIXT2|A10584T58O3B5Y|         5.0|     1394841600|        21|       810|\n",
      "|   B000GCGB3M|A105XFXLYACZZZ|         5.0|     1355184000|         1|       139|\n",
      "+-------------+--------------+------------+---------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered num of iteractions: 141608\n"
     ]
    }
   ],
   "source": [
    "user_inter_threshold = 10\n",
    "item_inter_threshold = 10\n",
    "\n",
    "# filter out the user and item with less than threshold interactions\n",
    "for dataset in datasets_to_download:\n",
    "    print('-----------------------------------')\n",
    "    print(f\"Dataset: {dataset}\")\n",
    "    inter_df = dfs[dataset][inter_map[dataset]]\n",
    "    \n",
    "    print(f'num of iteractions:',inter_df.count())\n",
    "\n",
    "    # print(f'num of {inter_map[dataset]}:',inter_df.count())\n",
    "    print(f'num of user_id:',inter_df.select('user_id:token').distinct().count())\n",
    "    print(f'num of item_id:',inter_df.select('item_id:token').distinct().count())\n",
    "    # count the number of interactions for each user and item and rename the count column\n",
    "    user_count_df = inter_df.groupBy('user_id:token').count().withColumnRenamed('count','count_user')\n",
    "    item_count_df = inter_df.groupBy('item_id:token').count().withColumnRenamed('count','count_item')\n",
    "\n",
    "    # append the count of user and item to the original df\n",
    "    inter_df = inter_df.join(user_count_df, on='user_id:token', how='inner')\n",
    "    inter_df = inter_df.join(item_count_df, on='item_id:token', how='inner')\n",
    "    inter_df.show(5)\n",
    "    \n",
    "    # filter out the user and item with less than threshold interactions\n",
    "    inter_df = inter_df.filter((col('count_user') >= user_inter_threshold) & (col('count_item') >= item_inter_threshold))\n",
    "    \n",
    "    print(f'filtered num of iteractions:',inter_df.count())\n",
    "    \n",
    "    # release the memory of dfs[dataset][inter_map[dataset]]\n",
    "    dfs[dataset][inter_map[dataset]] = inter_df.drop('count_user','count_item')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6675691f",
   "metadata": {
    "papermill": {
     "duration": 0.027709,
     "end_time": "2024-05-03T23:42:26.624353",
     "exception": false,
     "start_time": "2024-05-03T23:42:26.596644",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Output overlaped users between datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff5464b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:42:26.683019Z",
     "iopub.status.busy": "2024-05-03T23:42:26.682158Z",
     "iopub.status.idle": "2024-05-03T23:42:26.688116Z",
     "shell.execute_reply": "2024-05-03T23:42:26.687002Z"
    },
    "papermill": {
     "duration": 0.038601,
     "end_time": "2024-05-03T23:42:26.690589",
     "exception": false,
     "start_time": "2024-05-03T23:42:26.651988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# folder list of output folders\n",
    "output_folder_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeb6231d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:42:26.749784Z",
     "iopub.status.busy": "2024-05-03T23:42:26.748964Z",
     "iopub.status.idle": "2024-05-03T23:44:46.831397Z",
     "shell.execute_reply": "2024-05-03T23:44:46.830177Z"
    },
    "papermill": {
     "duration": 140.116277,
     "end_time": "2024-05-03T23:44:46.834931",
     "exception": false,
     "start_time": "2024-05-03T23:42:26.718654",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common users between amazon-digital-music and amazon-video-games\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "| user_id:token|\n",
      "+--------------+\n",
      "|A2P6QCZWW3H1X6|\n",
      "|A37Z81LW79DUZ8|\n",
      "|A1MCQLJGZ2ODCK|\n",
      "|A2Z4H7PQHDPUWF|\n",
      "|A15OGDJS69EUCP|\n",
      "+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of common_users: 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of interactino of common users in amazon-digital-music: 5366\n",
      "num of related items in the interaction: 3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density of amazon-digital-music inetraction : 0.004056433492096088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+------------+---------------+\n",
      "| user_id:token|item_id:token|rating:float|timestamp:float|\n",
      "+--------------+-------------+------------+---------------+\n",
      "|A105S56ODHGJEK|   B00000613H|         5.0|      990230400|\n",
      "|A105S56ODHGJEK|   B00001QGPS|         4.0|      944611200|\n",
      "|A105S56ODHGJEK|   B000002LJF|         5.0|      987120000|\n",
      "|A105S56ODHGJEK|   B000003C3V|         5.0|      944870400|\n",
      "|A105S56ODHGJEK|   B0000013GT|         5.0|      953769600|\n",
      "+--------------+-------------+------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of interactino of common users in amazon-video-games: 9055\n",
      "num of related items in the interaction: 5264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density of amazon-video-games inetraction : 0.002970868669847722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+------------+---------------+\n",
      "| user_id:token|item_id:token|rating:float|timestamp:float|\n",
      "+--------------+-------------+------------+---------------+\n",
      "|A2P6QCZWW3H1X6|   B003QOWPWS|         4.0|     1379116800|\n",
      "|A2P6QCZWW3H1X6|   B0016BVYA2|         4.0|     1372636800|\n",
      "|A2P6QCZWW3H1X6|   B00FM5IY4W|         2.0|     1389744000|\n",
      "|A2P6QCZWW3H1X6|   B002BSA298|         3.0|     1379030400|\n",
      "|A2P6QCZWW3H1X6|   B00D7NQP9M|         4.0|     1383868800|\n",
      "+--------------+-------------+------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "base_dataset = datasets_to_download[0]\n",
    "# find the common users between base_dataset and other datasets\n",
    "for j in range(1,len(datasets_to_download)):\n",
    "        dataset1 = base_dataset\n",
    "        dataset2 = datasets_to_download[j]\n",
    "        inter1 = dfs[dataset1][inter_map[dataset1]]\n",
    "        inter2 = dfs[dataset2][inter_map[dataset2]]\n",
    "        inter1.createOrReplaceTempView(\"inter1\")\n",
    "        inter2.createOrReplaceTempView(\"inter2\")\n",
    "\n",
    "        print(f\"Common users between {dataset1} and {dataset2}\")    \n",
    "        # get the distinct users and then intersect\n",
    "        inter1_dist = inter1.select('user_id:token').distinct()\n",
    "        # inter1_dist.show(5)\n",
    "        common_users = inter1_dist.join(inter2, inter1_dist['user_id:token'] == inter2['user_id:token'],'leftsemi')\n",
    "        common_users.show(5)\n",
    "\n",
    "        print(f'num of common_users:',common_users.count())\n",
    "        # print the items count of each inter of common users\n",
    "        inter1_com_user = inter1.join(common_users, 'user_id:token')\n",
    "        inter2_com_user = inter2.join(common_users, 'user_id:token')\n",
    "        # statictics of inter 1\n",
    "        inter1_com_user_count = inter1_com_user.count()\n",
    "        inter1_com_item_count = inter1_com_user.select('item_id:token').distinct().count()\n",
    "        print(f'num of interactino of common users in {dataset1}:',inter1_com_user_count)\n",
    "        print(f'num of related items in the interaction:',inter1_com_item_count)\n",
    "        print(f'density of {dataset1} inetraction :',inter1.count()/inter1_com_user_count/inter1_com_item_count)\n",
    "\n",
    "        # save filtered datasets to file\n",
    "        inter1_out_path = os.path.join(output_folder_path, f\"{dataset1}_{dataset2}\")\n",
    "        inter1_com_user.show(5)\n",
    "        inter1_com_user.repartition(1).write.option(\"header\", \"true\").csv(inter1_out_path, mode='overwrite', sep='\\t')\n",
    "        output_folder_list.append(inter1_out_path)\n",
    "        # output_folder_map[dataset1] = inter1_out_path\n",
    "        \n",
    "        # statictics of inter 2\n",
    "        inter2_com_user_count = inter2_com_user.count()\n",
    "        inter2_com_item_count = inter2_com_user.select('item_id:token').distinct().count()\n",
    "        print(f'num of interactino of common users in {dataset2}:',inter2_com_user_count)\n",
    "        print(f'num of related items in the interaction:',inter2_com_item_count)\n",
    "        print(f'density of {dataset2} inetraction :',inter2.count()/inter2_com_user_count/inter2_com_item_count)\n",
    "\n",
    "        # save filtered datasets to file\n",
    "        inter2_out_path = os.path.join(output_folder_path, f\"{dataset2}_{dataset1}\")\n",
    "        inter2_com_user.show(5) \n",
    "        inter2_com_user.repartition(1).write.option(\"header\", \"true\").csv(inter2_out_path, mode='overwrite', sep='\\t')\n",
    "        output_folder_list.append(inter2_out_path)\n",
    "        # output_folder_map[dataset2] = inter2_out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4363e1ba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:44:46.935414Z",
     "iopub.status.busy": "2024-05-03T23:44:46.934996Z",
     "iopub.status.idle": "2024-05-03T23:47:13.075791Z",
     "shell.execute_reply": "2024-05-03T23:47:13.074478Z"
    },
    "papermill": {
     "duration": 146.192307,
     "end_time": "2024-05-03T23:47:13.079105",
     "exception": false,
     "start_time": "2024-05-03T23:44:46.886798",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Common users among all datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "| user_id:token|\n",
      "+--------------+\n",
      "|A1KISBM4ST9O3U|\n",
      "|A2XQT9ZMXJ8NF3|\n",
      "|A3B01BU84T197B|\n",
      "+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of common_users after merge with amazon-digital-music: 5729\n",
      "Common users among all datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "| user_id:token|\n",
      "+--------------+\n",
      "| A12LH2100CKQO|\n",
      "|A1NTA4K5DS2V80|\n",
      "|A2P6QCZWW3H1X6|\n",
      "+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of common_users after merge with amazon-video-games: 265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "| user_id:token|\n",
      "+--------------+\n",
      "|A2P6QCZWW3H1X6|\n",
      "|A37Z81LW79DUZ8|\n",
      "|A2Z4H7PQHDPUWF|\n",
      "+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of interactino of common users in amazon-digital-music: 5366\n",
      "num of amazon-digital-music : 3002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density of amazon-digital-music inetraction : 0.004056433492096088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+------------+---------------+\n",
      "| user_id:token|item_id:token|rating:float|timestamp:float|\n",
      "+--------------+-------------+------------+---------------+\n",
      "|A105S56ODHGJEK|   B00000613H|         5.0|      990230400|\n",
      "|A105S56ODHGJEK|   B00001QGPS|         4.0|      944611200|\n",
      "|A105S56ODHGJEK|   B000002LJF|         5.0|      987120000|\n",
      "|A105S56ODHGJEK|   B000003C3V|         5.0|      944870400|\n",
      "|A105S56ODHGJEK|   B0000013GT|         5.0|      953769600|\n",
      "+--------------+-------------+------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of interactino of common users in amazon-video-games: 9055\n",
      "num of amazon-video-games : 5264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "density of amazon-video-games inetraction : 0.002970868669847722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+------------+---------------+\n",
      "| user_id:token|item_id:token|rating:float|timestamp:float|\n",
      "+--------------+-------------+------------+---------------+\n",
      "|A105S56ODHGJEK|   B0057FANEQ|         3.0|     1323820800|\n",
      "|A105S56ODHGJEK|   B000MUW98O|         3.0|     1205971200|\n",
      "|A105S56ODHGJEK|   B001NX6GBK|         4.0|     1270252800|\n",
      "|A105S56ODHGJEK|   B004R9OVEG|         5.0|     1307664000|\n",
      "|A105S56ODHGJEK|   B0058SHNF4|         4.0|     1326672000|\n",
      "+--------------+-------------+------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# find the common users among all downloaded datasets\n",
    "for dataset in datasets_to_download:\n",
    "    inter = dfs[dataset][inter_map[dataset]]\n",
    "    inter.createOrReplaceTempView(\"inter\")\n",
    "\n",
    "    print(f\"Common users among all datasets\")    \n",
    "    # get the distinct users and then intersect\n",
    "    inter_dist = inter.select('user_id:token').distinct()\n",
    "    inter_dist.show(3)\n",
    "    if dataset == datasets_to_download[0]:\n",
    "        common_users = inter_dist\n",
    "    else:\n",
    "        common_users = common_users.join(inter_dist, 'user_id:token','inner')\n",
    "    print(f'num of common_users after merge with {dataset}:',common_users.count())\n",
    "\n",
    "common_users.show(3)\n",
    "\n",
    "# export inter of common users to file\n",
    "for dataset in datasets_to_download:\n",
    "    inter = dfs[dataset][inter_map[dataset]]\n",
    "    inter.createOrReplaceTempView(\"inter\")\n",
    "    inter_com_user = inter.join(common_users, 'user_id:token')\n",
    "    inter_com_user_count = inter_com_user.count()\n",
    "    inter_com_item_count = inter_com_user.select('item_id:token').distinct().count()\n",
    "    print(f'num of interactino of common users in {dataset}:',inter_com_user_count)\n",
    "    print(f'num of {dataset} :',inter_com_item_count)\n",
    "    print(f'density of {dataset} inetraction :',inter.count()/inter_com_user_count/inter_com_item_count)\n",
    "\n",
    "    # save filtered datasets to file\n",
    "    inter_out_path = os.path.join(output_folder_path, f\"{dataset}_common\")\n",
    "    inter_com_user.show(5)\n",
    "    inter_com_user.repartition(1).write.option(\"header\", \"true\").csv(inter_out_path, mode='overwrite', sep='\\t')\n",
    "    output_folder_list.append(inter_out_path)\n",
    "    # output_folder_map[dataset] = inter_out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f53cf8c5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:47:13.238752Z",
     "iopub.status.busy": "2024-05-03T23:47:13.237675Z",
     "iopub.status.idle": "2024-05-03T23:47:21.939198Z",
     "shell.execute_reply": "2024-05-03T23:47:21.937529Z"
    },
    "papermill": {
     "duration": 8.774788,
     "end_time": "2024-05-03T23:47:21.942200",
     "exception": false,
     "start_time": "2024-05-03T23:47:13.167412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copy from input/amazon-digital-music/Amazon_Digital_Music.item to output/amazon-digital-music_amazon-video-games for amazon-digital-music \n",
      "copy from input/amazon-video-games/Amazon_Video_Games.item to output/amazon-video-games_amazon-digital-music for amazon-video-games \n",
      "copy from input/amazon-digital-music/Amazon_Digital_Music.item to output/amazon-digital-music_common for amazon-digital-music \n",
      "copy from input/amazon-video-games/Amazon_Video_Games.item to output/amazon-video-games_common for amazon-video-games \n"
     ]
    }
   ],
   "source": [
    "dataset_itemfile_map = {}\n",
    "def get_itemfile_path(dataset):\n",
    "    dataset_path = os.path.join(input_folder_path, dataset)\n",
    "    for file in os.listdir(dataset_path):\n",
    "        if file.endswith('.item'):\n",
    "            return os.path.join(dataset_path, file)\n",
    "    return None\n",
    "\n",
    "for ouptput_folder in output_folder_list:\n",
    "    # strip the dataset from the first part of folder\n",
    "    dataset = os.path.basename(ouptput_folder).split('_')[0]\n",
    "    # copy .item file from correonding input folder to output folder\n",
    "    itemfile_path = get_itemfile_path(dataset)\n",
    "    if itemfile_path:\n",
    "        print(f\"copy from {itemfile_path} to {ouptput_folder} for {dataset} \")\n",
    "        out_path = os.path.join(ouptput_folder, f\"{dataset}.item\")\n",
    "        !cp $itemfile_path $out_path\n",
    "    else:\n",
    "        print(f\"item file not found for {dataset}\")\n",
    "\n",
    "    for file in os.listdir(ouptput_folder):\n",
    "        # rename exported cvs as .inter\n",
    "        if file.endswith('.csv'):\n",
    "            # rename file to {folder}.inter\n",
    "            file_path = os.path.join(ouptput_folder, file)\n",
    "            out_path = os.path.join(ouptput_folder, f\"{dataset}.inter\")\n",
    "            !mv $file_path $out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14044195",
   "metadata": {
    "papermill": {
     "duration": 0.071815,
     "end_time": "2024-05-03T23:47:22.085128",
     "exception": false,
     "start_time": "2024-05-03T23:47:22.013313",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Analyze Chronicle Characteristics\n",
    "TBD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4f51df",
   "metadata": {
    "papermill": {
     "duration": 0.06928,
     "end_time": "2024-05-03T23:47:22.224829",
     "exception": false,
     "start_time": "2024-05-03T23:47:22.155549",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sampling\n",
    "Stratified sampling based on hotness(interaction rate) of items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b436890",
   "metadata": {
    "papermill": {
     "duration": 0.0707,
     "end_time": "2024-05-03T23:47:22.366700",
     "exception": false,
     "start_time": "2024-05-03T23:47:22.296000",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## release all the resources "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caae2ece",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-03T23:47:22.524596Z",
     "iopub.status.busy": "2024-05-03T23:47:22.523638Z",
     "iopub.status.idle": "2024-05-03T23:47:23.183074Z",
     "shell.execute_reply": "2024-05-03T23:47:23.182075Z"
    },
    "papermill": {
     "duration": 0.739199,
     "end_time": "2024-05-03T23:47:23.186016",
     "exception": false,
     "start_time": "2024-05-03T23:47:22.446817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# unpersist the dfs\n",
    "for dataset in datasets_to_download:\n",
    "    for key in dfs[dataset]:\n",
    "        dfs[dataset][key].unpersist()\n",
    "        \n",
    "# Stop the Spark session\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a0a690",
   "metadata": {
    "papermill": {
     "duration": 0.07138,
     "end_time": "2024-05-03T23:47:23.330178",
     "exception": false,
     "start_time": "2024-05-03T23:47:23.258798",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Sammary\n",
    "Spark is a powerful and efficient tool to handle sample on large scale of data. \n",
    "* flexible and powerful functionality\n",
    "* runs super fast even on my laptop\n",
    "* easy to apply to similar datasets(Amazon have dataset of different categories), I only focused on one categoy this time. "
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 468.828256,
   "end_time": "2024-05-03T23:47:26.024708",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-03T23:39:37.196452",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
