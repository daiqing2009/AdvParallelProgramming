{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling large Datasets\n",
    "In data processing, a great deal of computing involves analysing large amounts of text mixed with numerical data.  This is what Spark is particularly suited for. \n",
    "### Tasks to be finished\n",
    "* Analyze the data find out the basic distribution characteristics\n",
    "* Sampling with different combination of methods\n",
    "* Sampling taking consideration with related data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Amazon Movie dataset\n",
    "INTERACTIONs DATASET FILE DESCRIPTION\n",
    "------------------------------------------------------------------------------------\n",
    "------------------------------------------------------------------------------------\n",
    "The file Amazon_xx.inter comprising the ratings of users over the items.\n",
    "Each record/line in the file has the following fields: user_id, item_id, rating and timestamp.\n",
    "\n",
    "user_id: the id of the users and its type is token. \n",
    "item_id: the id of the items and its type is token.\n",
    "rating: the rating of the users over the item, and its type is float.\n",
    "timestamp: the UNIX time of the interaction, and its type is float.\n",
    "\n",
    "ITEMS INFORMATION DATASET FILE DESCRIPTION\n",
    "------------------------------------------------------------------------------------\n",
    "------------------------------------------------------------------------------------\n",
    "The file Amazon_xx.item comprising the attributes of the items.\n",
    "Each record/line in the file has the following fields: item_id, title, price, sales_type, sales_rank, brand, categories\n",
    " \n",
    "item_id: the id of the item and its type is token.\n",
    "title: the title of the item, and its type is token.\n",
    "price: the price of the item, and its type is float.\n",
    "sales_type: the type sales rank in, and its type is token. \n",
    "sales_rank: sales rank, and its type is float.\n",
    "brand: the brand name of the item, and its type is token.\n",
    "categories: the categories of the item, and its type is token_seq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName(\"Amazon Sampling\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------+------------+---------------+\n",
      "| user_id:token|item_id:token|rating:float|timestamp:float|\n",
      "+--------------+-------------+------------+---------------+\n",
      "|A3478QRKQDOPQ2|   0001527665|         5.0|     1362960000|\n",
      "|A2VHSG6TZHU1OB|   0001527665|         5.0|     1361145600|\n",
      "|A23EJWOW1TLENE|   0001527665|         5.0|     1358380800|\n",
      "|A1KM9FNEJ8Q171|   0001527665|         5.0|     1357776000|\n",
      "|A38LY2SSHVHRYB|   0001527665|         4.0|     1356480000|\n",
      "+--------------+-------------+------------+---------------+\n",
      "\n",
      "+-------------+--------------------+--------------------+-----------+----------------+----------------+\n",
      "|item_id:token|         title:token|categories:token_seq|brand:token|sales_type:token|sales_rank:float|\n",
      "+-------------+--------------------+--------------------+-----------+----------------+----------------+\n",
      "|   0000695009|Understanding Sei...|            'Movies'|       null|     Movies & TV|        886503.0|\n",
      "|   0000791156|Spirit Led&mdash;...|            'Movies'|       null|     Movies & TV|        342688.0|\n",
      "|   0000143529|My Fair Pastry (G...|            'Movies'|Alton Brown|     Movies & TV|        370026.0|\n",
      "|   0000143588|Barefoot Contessa...|            'Movies'| Ina Garten|     Movies & TV|        342914.0|\n",
      "|   0000143502|Rise and Swine (G...|            'Movies'|Alton Brown|     Movies & TV|        351684.0|\n",
      "+-------------+--------------------+--------------------+-----------+----------------+----------------+\n",
      "\n",
      "root\n",
      " |-- user_id:token: string (nullable = true)\n",
      " |-- item_id:token: string (nullable = true)\n",
      " |-- rating:float: string (nullable = true)\n",
      " |-- timestamp:float: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'DataFrame' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# make timestamp more human-readible \u001b[39;00m\n\u001b[1;32m     24\u001b[0m df_movietv5_inter\u001b[38;5;241m.\u001b[39mprintSchema()\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mdf_movietv5_inter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtimestamp:float\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DateType\n\u001b[1;32m     28\u001b[0m df_movietv5_inter\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp:date\u001b[39m\u001b[38;5;124m'\u001b[39m, df_movietv5_inter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimestamp:float\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcast(DateType()))\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DataFrame' object is not callable"
     ]
    }
   ],
   "source": [
    "#Run the code in this box, and then continue running the boxes (in order) until the end of lesson.\n",
    "# import pyspark\n",
    "# conf = pyspark.SparkConf().setAppName(\"Amazon Sampling\")\n",
    "\n",
    "# try:\n",
    "#     sc = pyspark.SparkContext(conf=conf)\n",
    "# except:\n",
    "#     print(\"Warning : a SparkContext already exists.\")\n",
    "\n",
    "# readin the top5 samples to get a glimpse of data\n",
    "movietv5_inter_path = \"./Amazon/5Lines/Amazon_Movies_and_TV.inter\"\n",
    "movietv5_item_path = \"./Amazon/5Lines/Amazon_Movies_and_TV.item\"\n",
    "\n",
    "\n",
    "\n",
    "# read from file into dataframe\n",
    "df_movietv5_inter= spark.read.option(\"delimiter\",'\\t').option(\"header\", True).csv(movietv5_inter_path)\n",
    "df_movietv5_inter.show()\n",
    "\n",
    "df_movietv5_item= spark.read.option(\"delimiter\",'\\t').option(\"header\", True).csv(movietv5_item_path)\n",
    "df_movietv5_item.show()\n",
    "\n",
    "# make timestamp more human-readible \n",
    "print(df_movietv5_inter[\"timestamp:float\"])\n",
    "\n",
    "from pyspark.sql.types import DateType\n",
    "df_movietv5_inter.withColumn('timestamp:date', df_movietv5_inter[\"timestamp:float\"].cast(DateType())).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## General Data Analysis\n",
    "* uniqueness\n",
    "* completness \n",
    "* lingage, concentration and sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of df_movietv_inter= 8765568 \n",
      "\n",
      "num of df_movietv_item= 181839\n",
      "Row(item_id:token='0000695009', title:token='Understanding Seizures and Epilepsy', categories:token_seq=\"'Movies'\", brand:token=None, sales_type:token='Movies & TV', sales_rank:float='886503.0')\n",
      "num of filtered movietv iterm 181839\n"
     ]
    }
   ],
   "source": [
    "movietv_inter_path = \"./Amazon/Amazon_Movies_and_TV/Amazon_Movies_and_TV.inter\"\n",
    "movietv_item_path = \"./Amazon/Amazon_Movies_and_TV/Amazon_Movies_and_TV.item\"\n",
    "# read from file into dataframe\n",
    "df_movietv_inter= spark.read.option(\"delimiter\",'\\t').option(\"header\", True).csv(movietv_inter_path)\n",
    "\n",
    "df_movietv_item= spark.read.option(\"delimiter\",'\\t').option(\"header\", True).csv(movietv_item_path)\n",
    "\n",
    "print(\"num of df_movietv_inter=\",df_movietv_inter.count(),'\\n')\n",
    "print('num of df_movietv_item=',df_movietv_item.count())\n",
    "\n",
    "def is_author_categories_defined(record):\n",
    "    # print(record)\n",
    "    return \"title:token\" and \"categories:token_seq\" in record\n",
    "\n",
    "df_movietv_item_filt = df_movietv_item.rdd.filter(is_author_categories_defined)\n",
    "print(df_movietv_item_filt.first())\n",
    "print(\"num of filtered movietv iterm\", df_movietv_item_filt.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniquenss\n",
    "* no duplicated item_id\n",
    "* no duplicated interaction from same user_id on same item_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PipelinedRDD' object has no attribute 'rdd'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# extract item_ids\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m movietv_item_ids \u001b[38;5;241m=\u001b[39m \u001b[43mdf_movietv_item_filt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrdd\u001b[49m\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m item: item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id:token\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(movietv_item_ids\u001b[38;5;241m.\u001b[39mfirst())\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# check if any dulicpated \u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PipelinedRDD' object has no attribute 'rdd'"
     ]
    }
   ],
   "source": [
    "# extract item_ids\n",
    "movietv_item_ids = df_movietv_item_filt.map(lambda item: item['item_id:token'])\n",
    "\n",
    "print(movietv_item_ids.first())\n",
    "# check if any dulicpated \n",
    "print(\"Duplicate item by ID:\", movietv_item_ids.count() - movietv_item_ids.distinct().count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(user_id:token='A3478QRKQDOPQ2', item_id:token='0001527665', rating:float='5.0', timestamp:float='1362960000', comb_key='A3478QRKQDOPQ20001527665')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m df_movietv_inter \u001b[38;5;241m=\u001b[39m df_movietv_inter\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomb_key\u001b[39m\u001b[38;5;124m\"\u001b[39m, concat(df_movietv_inter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id:token\u001b[39m\u001b[38;5;124m\"\u001b[39m],df_movietv_inter[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem_id:token\u001b[39m\u001b[38;5;124m\"\u001b[39m]))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_movietv_inter\u001b[38;5;241m.\u001b[39mfirst())\n\u001b[0;32m----> 7\u001b[0m movietv_inter_comb_keys \u001b[38;5;241m=\u001b[39m \u001b[43mdf_movietv_inter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m(\u001b[38;5;28;01mlambda\u001b[39;00m inter: inter[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomb_key\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDuplicate interaction by combined(user, item):\u001b[39m\u001b[38;5;124m\"\u001b[39m, movietv_inter_comb_keys\u001b[38;5;241m.\u001b[39mcount() \u001b[38;5;241m-\u001b[39m movietv_inter_comb_keys\u001b[38;5;241m.\u001b[39mdistinct()\u001b[38;5;241m.\u001b[39mcount())\n",
      "File \u001b[0;32m~/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/sql/dataframe.py:2977\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2944\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   2945\u001b[0m \n\u001b[1;32m   2946\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2974\u001b[0m \u001b[38;5;124;03m+---+\u001b[39;00m\n\u001b[1;32m   2975\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2976\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 2977\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   2978\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name)\n\u001b[1;32m   2979\u001b[0m     )\n\u001b[1;32m   2980\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   2981\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "# combine \n",
    "from pyspark.sql.functions import concat\n",
    "df_movietv_inter = df_movietv_inter.withColumn(\"comb_key\", concat(df_movietv_inter[\"user_id:token\"],df_movietv_inter[\"item_id:token\"]))\n",
    "\n",
    "print(df_movietv_inter.first())\n",
    "\n",
    "movietv_inter_comb_keys = df_movietv_inter.rdd.map(lambda inter: inter['comb_key'])\n",
    "\n",
    "print(\"Duplicate interaction by combined(user, item):\", movietv_inter_comb_keys.count() - movietv_inter_comb_keys.distinct().count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the completeness \n",
    "* completeness attributes in item data \n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/05 17:33:09 ERROR Executor: Exception in task 0.0 in stage 56.0 (TID 120)\n",
      "org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 830, in main\n",
      "    process()\n",
      "  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 822, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/rdd.py\", line 2830, in takeUpToNumLeft\n",
      "    yield next(iterator)\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/bj/spr6xdy950jf8sj2svjhs0vh0000gn/T/ipykernel_91395/1940389966.py\", line 1, in <lambda>\n",
      "TypeError: string indices must be integers, not 'str'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:767)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:749)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:179)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "24/04/05 17:33:09 WARN TaskSetManager: Lost task 0.0 in stage 56.0 (TID 120) (10.0.0.13 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n",
      "  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 830, in main\n",
      "    process()\n",
      "  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 822, in process\n",
      "    serializer.dump_stream(out_iter, outfile)\n",
      "  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n",
      "    vs = list(itertools.islice(iterator, batch))\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/rdd.py\", line 2830, in takeUpToNumLeft\n",
      "    yield next(iterator)\n",
      "          ^^^^^^^^^^^^^^\n",
      "  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/var/folders/bj/spr6xdy950jf8sj2svjhs0vh0000gn/T/ipykernel_91395/1940389966.py\", line 1, in <lambda>\n",
      "TypeError: string indices must be integers, not 'str'\n",
      "\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:767)\n",
      "\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:749)\n",
      "\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n",
      "\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n",
      "\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n",
      "\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n",
      "\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n",
      "\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n",
      "\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n",
      "\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n",
      "\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n",
      "\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n",
      "\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n",
      "\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n",
      "\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n",
      "\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n",
      "\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n",
      "\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:179)\n",
      "\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303)\n",
      "\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n",
      "\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n",
      "\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n",
      "\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n",
      "\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:748)\n",
      "\n",
      "24/04/05 17:33:09 ERROR TaskSetManager: Task 0 in stage 56.0 failed 1 times; aborting job\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 56.0 failed 1 times, most recent failure: Lost task 0.0 in stage 56.0 (TID 120) (10.0.0.13 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 830, in main\n    process()\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 822, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/rdd.py\", line 2830, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/bj/spr6xdy950jf8sj2svjhs0vh0000gn/T/ipykernel_91395/1940389966.py\", line 1, in <lambda>\nTypeError: string indices must be integers, not 'str'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:767)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:749)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:179)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:179)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 830, in main\n    process()\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 822, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/rdd.py\", line 2830, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/bj/spr6xdy950jf8sj2svjhs0vh0000gn/T/ipykernel_91395/1940389966.py\", line 1, in <lambda>\nTypeError: string indices must be integers, not 'str'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:767)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:749)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:179)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m item_meta\u001b[38;5;241m=\u001b[39mmovietv_item_ids\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m item:item[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id:token\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# print(\"type of item_meta is\",type(item_meta.first()),'\\n')\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst element of adelaide_meta is \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\u001b[43mitem_meta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkeys of item_meta\u001b[39m\u001b[38;5;124m\"\u001b[39m,item_meta\u001b[38;5;241m.\u001b[39mfirst()\u001b[38;5;241m.\u001b[39mkeys(),\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      7\u001b[0m adelaide_key_value \u001b[38;5;241m=\u001b[39m adelaide_keys\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m key: (key, \u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/rdd.py:2869\u001b[0m, in \u001b[0;36mRDD.first\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2843\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfirst\u001b[39m(\u001b[38;5;28mself\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRDD[T]\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m   2844\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2845\u001b[0m \u001b[38;5;124;03m    Return the first element in this RDD.\u001b[39;00m\n\u001b[1;32m   2846\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2867\u001b[0m \u001b[38;5;124;03m    ValueError: RDD is empty\u001b[39;00m\n\u001b[1;32m   2868\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2869\u001b[0m     rs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtake\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2870\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rs:\n\u001b[1;32m   2871\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m rs[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/rdd.py:2836\u001b[0m, in \u001b[0;36mRDD.take\u001b[0;34m(self, num)\u001b[0m\n\u001b[1;32m   2833\u001b[0m         taken \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2835\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(partsScanned, \u001b[38;5;28mmin\u001b[39m(partsScanned \u001b[38;5;241m+\u001b[39m numPartsToTry, totalParts))\n\u001b[0;32m-> 2836\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtakeUpToNumLeft\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2838\u001b[0m items \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m   2839\u001b[0m partsScanned \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m numPartsToTry\n",
      "File \u001b[0;32m~/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/context.py:2319\u001b[0m, in \u001b[0;36mSparkContext.runJob\u001b[0;34m(self, rdd, partitionFunc, partitions, allowLocal)\u001b[0m\n\u001b[1;32m   2317\u001b[0m mappedRDD \u001b[38;5;241m=\u001b[39m rdd\u001b[38;5;241m.\u001b[39mmapPartitions(partitionFunc)\n\u001b[1;32m   2318\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2319\u001b[0m sock_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPythonRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jsc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmappedRDD\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jrdd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartitions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(_load_from_socket(sock_info, mappedRDD\u001b[38;5;241m.\u001b[39m_jrdd_deserializer))\n",
      "File \u001b[0;32m~/miniconda3/envs/CP631/lib/python3.12/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1323\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdeco\u001b[39m(\u001b[38;5;241m*\u001b[39ma: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m Py4JJavaError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/miniconda3/envs/CP631/lib/python3.12/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[38;5;241m=\u001b[39m OUTPUT_CONVERTER[\u001b[38;5;28mtype\u001b[39m](answer[\u001b[38;5;241m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m answer[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn error occurred while calling \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m. Trace:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{3}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[38;5;28mformat\u001b[39m(target_id, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 56.0 failed 1 times, most recent failure: Lost task 0.0 in stage 56.0 (TID 120) (10.0.0.13 executor driver): org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 830, in main\n    process()\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 822, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/rdd.py\", line 2830, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/bj/spr6xdy950jf8sj2svjhs0vh0000gn/T/ipykernel_91395/1940389966.py\", line 1, in <lambda>\nTypeError: string indices must be integers, not 'str'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:767)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:749)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:179)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2785)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2721)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2720)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2720)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1206)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1206)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2984)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2923)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2912)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:971)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2263)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2284)\n\tat org.apache.spark.SparkContext.runJob(SparkContext.scala:2303)\n\tat org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:179)\n\tat org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.lang.Thread.run(Thread.java:748)\nCaused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 830, in main\n    process()\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/worker.py\", line 822, in process\n    serializer.dump_stream(out_iter, outfile)\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/serializers.py\", line 274, in dump_stream\n    vs = list(itertools.islice(iterator, batch))\n         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/rdd.py\", line 2830, in takeUpToNumLeft\n    yield next(iterator)\n          ^^^^^^^^^^^^^^\n  File \"/Users/qing/miniconda3/envs/CP631/lib/python3.12/site-packages/pyspark/python/lib/pyspark.zip/pyspark/util.py\", line 81, in wrapper\n    return f(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^\n  File \"/var/folders/bj/spr6xdy950jf8sj2svjhs0vh0000gn/T/ipykernel_91395/1940389966.py\", line 1, in <lambda>\nTypeError: string indices must be integers, not 'str'\n\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.handlePythonException(PythonRunner.scala:561)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:767)\n\tat org.apache.spark.api.python.PythonRunner$$anon$3.read(PythonRunner.scala:749)\n\tat org.apache.spark.api.python.BasePythonRunner$ReaderIterator.hasNext(PythonRunner.scala:514)\n\tat org.apache.spark.InterruptibleIterator.hasNext(InterruptibleIterator.scala:37)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat org.apache.spark.InterruptibleIterator.foreach(InterruptibleIterator.scala:28)\n\tat scala.collection.generic.Growable.$plus$plus$eq(Growable.scala:62)\n\tat scala.collection.generic.Growable.$plus$plus$eq$(Growable.scala:53)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:105)\n\tat scala.collection.mutable.ArrayBuffer.$plus$plus$eq(ArrayBuffer.scala:49)\n\tat scala.collection.TraversableOnce.to(TraversableOnce.scala:366)\n\tat scala.collection.TraversableOnce.to$(TraversableOnce.scala:364)\n\tat org.apache.spark.InterruptibleIterator.to(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toBuffer(TraversableOnce.scala:358)\n\tat scala.collection.TraversableOnce.toBuffer$(TraversableOnce.scala:358)\n\tat org.apache.spark.InterruptibleIterator.toBuffer(InterruptibleIterator.scala:28)\n\tat scala.collection.TraversableOnce.toArray(TraversableOnce.scala:345)\n\tat scala.collection.TraversableOnce.toArray$(TraversableOnce.scala:339)\n\tat org.apache.spark.InterruptibleIterator.toArray(InterruptibleIterator.scala:28)\n\tat org.apache.spark.api.python.PythonRDD$.$anonfun$runJob$1(PythonRDD.scala:179)\n\tat org.apache.spark.SparkContext.$anonfun$runJob$5(SparkContext.scala:2303)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:92)\n\tat org.apache.spark.TaskContext.runTaskWithListeners(TaskContext.scala:161)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:139)\n\tat org.apache.spark.executor.Executor$TaskRunner.$anonfun$run$3(Executor.scala:554)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1529)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:557)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\t... 1 more\n"
     ]
    }
   ],
   "source": [
    "item_meta=movietv_item_ids.map(lambda item:item['item_id:token'])\n",
    "# print(\"type of item_meta is\",type(item_meta.first()),'\\n')\n",
    "print(\"first element of adelaide_meta is \\n\",item_meta.first())\n",
    "\n",
    "print(\"keys of item_meta\",item_meta.first().keys(),'\\n')\n",
    "\n",
    "item_keys = item_meta.flatMap(lambda rec: rec.keys())\n",
    "\n",
    "#frequency of each key.\n",
    "adelaide_key_value = item_keys.map(lambda key: (key, 1))\n",
    "adelaide_key_value.first()\n",
    "\n",
    "from operator import add\n",
    "\n",
    "adelaide_agg = adelaide_key_value.reduceByKey(add)\n",
    "adelaide_agg.collectAsMap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compare the lengths of the original and new RDDs to see how many bad values have been filtered out.  Note that Spark uses lazy evaluation, so the actual computation and creation of new dataset is not actually carried out until its values are used.  So the line above might have evaluated in a fraction of a second, because no actual work has been done.  The RDD would actually be constructed in cell below, where its elements are actually accessed.  We can see that the new set has fewer elements than the original set, so some bad entries have indeed been present and are now filtered out.  First we also print the first elements of the original and new RDD just to see that they look reasonable.  This is a good habit to get into any time you generate a new dataset from an existing one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caching\n",
    "\n",
    "When we expect to operate frequently on the same dataset, it might be useful to tell Spark to keep it in memory.  For that, we can use the cache() method.  If you plan to do a large operation on an RDD, apply the cache() method to it first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Characteristic Analysis\n",
    "* skewness of items\n",
    "  * attribute year\n",
    "  * category\n",
    "* sparsity of interactions\n",
    "  * too few interaction on \n",
    "  * "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:14: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:14: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/bj/spr6xdy950jf8sj2svjhs0vh0000gn/T/ipykernel_8561/3494965734.py:14: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  birth, death = re.findall('\\d+', birth_death)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def process_name_birth_death(record):\n",
    "    author = record.get('author', None)\n",
    "    if author:\n",
    "        author = author.strip()\n",
    "        # Remove trailing dot\n",
    "        if '.' == author[-1]:\n",
    "            author = author[:-1]\n",
    "        try:\n",
    "            lastname, firstname, birth_death = author.split(',')\n",
    "        except ValueError:\n",
    "            return record\n",
    "        try:\n",
    "            birth, death = re.findall('\\d+', birth_death)\n",
    "        except ValueError:\n",
    "            return record\n",
    "        record['author_lastname'] = lastname.strip()\n",
    "        record['author_firstname'] = firstname.strip()\n",
    "        record['author_birth'] = int(birth)\n",
    "        record['author_death'] = int(death)\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first run this function on a single dictionary to make sure it works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'publisher': 'The University of Adelaide Library',\n",
       " '@type': 'Book',\n",
       " '@context': 'http://schema.org',\n",
       " 'url': 'https://ebooks.adelaide.edu.au/l/lefanu/aungier/',\n",
       " 'dateCreated': '1851',\n",
       " 'datePublished': '2010-03-27',\n",
       " 'author': 'Le Fanu, Joseph Sheridan, 1814-1873.',\n",
       " 'name': 'An Account of Some Strange Disturbances in Aungier Street',\n",
       " 'dateModified': '2014-02-25',\n",
       " 'keywords': 'Literature',\n",
       " 'image': 'https://ebooks.adelaide.edu.au/l/lefanu/aungier/cover.jpg',\n",
       " 'description': 'An Account of Some Strange Disturbances in Aungier Street / J. Sheridan Le Fanu',\n",
       " 'inLanguage': 'en',\n",
       " 'author_lastname': 'Le Fanu',\n",
       " 'author_firstname': 'Joseph Sheridan',\n",
       " 'author_birth': 1814,\n",
       " 'author_death': 1873}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=adelaide_meta.first()\n",
    "process_name_birth_death(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once it is verified to work, we apply it to the whole RDD through a map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "adelaide_meta_val = adelaide_meta.map(process_name_birth_death)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify we did this correctly by looking the the first two elements of the resulting RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'publisher': 'The University of Adelaide Library',\n",
       "  '@type': 'Book',\n",
       "  '@context': 'http://schema.org',\n",
       "  'url': 'https://ebooks.adelaide.edu.au/l/lefanu/aungier/',\n",
       "  'dateCreated': '1851',\n",
       "  'datePublished': '2010-03-27',\n",
       "  'author': 'Le Fanu, Joseph Sheridan, 1814-1873.',\n",
       "  'name': 'An Account of Some Strange Disturbances in Aungier Street',\n",
       "  'dateModified': '2014-02-25',\n",
       "  'keywords': 'Literature',\n",
       "  'image': 'https://ebooks.adelaide.edu.au/l/lefanu/aungier/cover.jpg',\n",
       "  'description': 'An Account of Some Strange Disturbances in Aungier Street / J. Sheridan Le Fanu',\n",
       "  'inLanguage': 'en',\n",
       "  'author_lastname': 'Le Fanu',\n",
       "  'author_firstname': 'Joseph Sheridan',\n",
       "  'author_birth': 1814,\n",
       "  'author_death': 1873},\n",
       " {'publisher': 'The University of Adelaide Library',\n",
       "  'image': 'https://ebooks.adelaide.edu.au/b/benson/ef/and-the-dead-spake/cover.jpg',\n",
       "  'url': 'https://ebooks.adelaide.edu.au/b/benson/ef/and-the-dead-spake/',\n",
       "  'name': 'And the Dead Spake',\n",
       "  'description': 'And the Dead Spake / E. F. Benson',\n",
       "  '@context': 'http://schema.org',\n",
       "  'keywords': 'Literature',\n",
       "  'author': 'Benson, E. F. (Edward Frederic), 1867-1940',\n",
       "  '@type': 'Book',\n",
       "  'inLanguage': 'en',\n",
       "  'author_lastname': 'Benson',\n",
       "  'author_firstname': 'E. F. (Edward Frederic)',\n",
       "  'author_birth': 1867,\n",
       "  'author_death': 1940}]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adelaide_meta_val.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also apply a transformation to change works created before year 0 CE to have a negative value, which might help in our analysis.  The function to do this is below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/var/folders/bj/spr6xdy950jf8sj2svjhs0vh0000gn/T/ipykernel_8561/3654922853.py:3: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  dates = re.findall('\\d+', record['dateCreated'])\n"
     ]
    }
   ],
   "source": [
    "def convert_dateCreated(record):\n",
    "    if 'dateCreated' in record:\n",
    "        dates = re.findall('\\d+', record['dateCreated'])\n",
    "        if len(dates) > 0:\n",
    "            date = int(dates[0])\n",
    "            # Check if the date is before common era\n",
    "            if re.match(r'BC|bc|BCE|bce', record['dateCreated']):\n",
    "                date *= -1\n",
    "            record['dateCreated'] = date\n",
    "        else:\n",
    "            del record['dateCreated']\n",
    "    return record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the function through a map.  In this case the new RDD overwrites the old RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "adelaide_meta_val = adelaide_meta_val.map(convert_dateCreated)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First analysis: authors' life expectancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the metadata RDD filtered to our satisfaction, we can do some analysis on the data it contains.  To do this, we write a function that computes the age (at death) of the author.  It is not a perfect function in that it will get confused if an author's lifetime spanned year 0, but it's good enough for our purposes.  After the function is defined and applied through map() to the RDD, we then apply the count by countByValue method, which will count how many times each value is present and produce a list holding this information.  The resulting list is not an RDD, so we can work with it like with other standard Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {59: 91, 73: 222, 78: 77, 83: 35, 58: 97, 48: 21, 49: 11, 47: 106, 84: 26, 76: 22, 74: 70, None: 478, 51: 86, 43: 318, 67: 130, 88: 38, 57: 25, 62: 85, 65: 170, 61: 59, 90: 10, 69: 48, 46: 97, 44: 96, 56: 54, 77: 88, 45: 58, 80: 146, 50: 11, 82: 111, 81: 75, 70: 58, 41: 13, 60: 48, 85: 15, 33: 7, 55: 84, 68: 97, 52: 97, 72: 48, 40: 61, 75: 85, 66: 108, 71: 86, 39: 12, 32: 2, 64: 39, 38: 50, 93: 8, 94: 11, 29: 11, 87: 5, 54: 20, 89: 22, 37: 12, 79: 37, 92: 2, 86: 7, 30: 9, 36: 7, 26: 13, 27: 1, 42: 9, 63: 16, 34: 10, 53: 3, 101: 1, 35: 7, 91: 1, 31: 1})\n"
     ]
    }
   ],
   "source": [
    "def compute_age(rec):\n",
    "    \"\"\"Compute the age of an author when it died\n",
    "    based on its year of birth and death.\n",
    "    \"\"\"\n",
    "    if 'author_birth' and 'author_death' in rec:\n",
    "        birth, death =  rec['author_birth'], rec['author_death']\n",
    "        if birth < death:\n",
    "            return death - birth\n",
    "        else:\n",
    "            # If year of birth is greater than year of death the\n",
    "            # author was born in BCE. This will not be correct for authors \n",
    "            # who were alive 1 CE, crossing over the BCE and CE boundary,\n",
    "            # but we will not worry about this artifact in this exercise.\n",
    "            return birth - death\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "age_frequency = adelaide_meta_val.map(compute_age).countByValue()\n",
    "\n",
    "print(age_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand this data we use the standard Python plotting library matplotlib.  Again, as with BeautifulSoup, mastering this library is outside the scope of this course.  Here we are using it as an utility.  If you want to understand it in more detail, refer to the tutorials available online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 73, 78, 83, 58, 48, 49, 47, 84, 76, 74, None, 51, 43, 67, 88, 57, 62, 65, 61, 90, 69, 46, 44, 56, 77, 45, 80, 50, 82, 81, 70, 41, 60, 85, 33, 55, 68, 52, 72, 40, 75, 66, 71, 39, 32, 64, 38, 93, 94, 29, 87, 54, 89, 37, 79, 92, 86, 30, 36, 26, 27, 42, 63, 34, 53, 101, 35, 91, 31]\n",
      "[91, 222, 77, 35, 97, 21, 11, 106, 26, 22, 70, 478, 86, 318, 130, 38, 25, 85, 170, 59, 10, 48, 97, 96, 54, 88, 58, 146, 11, 111, 75, 58, 13, 48, 15, 7, 84, 97, 97, 48, 61, 85, 108, 86, 12, 2, 39, 50, 8, 11, 11, 5, 20, 22, 12, 37, 2, 7, 9, 7, 13, 1, 9, 16, 10, 3, 1, 7, 1, 1]\n",
      "[73 78 83 58 48 49 47 84 76 74 None 51 43 67 88 57 62 65 61 90 69 46 44 56\n",
      " 77 45 80 50 82 81 70 41 60 85 33 55 68 52 72 40 75 66 71 39 32 64 38 93\n",
      " 94 29 87 54 89 37 79 92 86 30 36 26 27 42 63 34 53 101 35 91 31]\n",
      "[222  77  35  97  21  11 106  26  22  70 478  86 318 130  38  25  85 170\n",
      "  59  10  48  97  96  54  88  58 146  11 111  75  58  13  48  15   7  84\n",
      "  97  97  48  61  85 108  86  12   2  39  50   8  11  11   5  20  22  12\n",
      "  37   2   7   9   7  13   1   9  16  10   3   1   7   1   1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bj/spr6xdy950jf8sj2svjhs0vh0000gn/T/ipykernel_8561/3192641303.py:17: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \".b-\" (-> linestyle='-'). The keyword argument will take precedence.\n",
      "  plt.plot(x,y,'.b-',linestyle='None')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# need to add plot\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "age=list(age_frequency.keys())\n",
    "frequency=list(age_frequency.values())\n",
    "print(age)\n",
    "print(frequency)\n",
    "x=numpy.array(age[1:]) # not taking the \"None\" key by starting at position 1\n",
    "y=numpy.array(frequency[1:]) # not taking the \"None\" frequency by starting at position 1\n",
    "print(x)\n",
    "print(y)\n",
    "#fig,ax=plt.subplots()\n",
    "#ax.plot(x,y)\n",
    "#plt.scatter(x,y)\n",
    "plt.plot(x,y,'.b-',linestyle='None')\n",
    "plt.show()\n",
    "#run this box again if figure does not appear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(graphic generated by me in this notebook)\n",
    "\n",
    "Our data has a strange spike at 43. Could we be doing something wrong?  Yes, we are considering multiple books by the same author separately.   Therefore, if there is one particular author that happens to be the author of a large number of books in this database, our results will be skewed.  To fix this, lets make a new RDD that consists of tuples with three elements each for an author: first name, last name, age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Joseph Sheridan', 'Le Fanu', 59),\n",
       " ('E. F. (Edward Frederic)', 'Benson', 73),\n",
       " ('Jonathan', 'Swift', 78),\n",
       " ('Augustine', 'Birrell', 83),\n",
       " ('Nellie', 'Bly', 58)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_name_age(rec):\n",
    "    age = compute_age(rec)\n",
    "    lastname = rec['author_lastname']\n",
    "    firstname = rec['author_firstname']\n",
    "    return firstname, lastname, age\n",
    "\n",
    "authors = adelaide_meta_val.filter(lambda rec: 'author_lastname' in rec).map(retrieve_name_age)\n",
    "authors.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply the distinct() method to this RDD to eliminate indentical elements.  In the resulting dataset, each author is listed only once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:=====================>                                 (10 + 10) / 26]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3606 583\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "unique_authors = authors.distinct()\n",
    "print(authors.count(),unique_authors.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that there are only 583 unique authors for our 3606 books.  We make the RDD containing only the age, and apply countByValue() method to get data for a new histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_frequency2 = unique_authors.map(lambda tup: tup[2]).countByValue()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then plot it again with matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84, 74, 45, 80, 66, 29, 92, 30, 55, 83, 59, 78, 62, 46, 82, 54, 63, 58, 72, 75, 79, 68, 88, 71, 85, 73, 57, 51, 38, 47, 31, 61, 77, 56, 41, 34, 69, 50, 33, 26, 90, 35, 53, 81, 39, 37, 42, 101, 70, 65, 67, 64, 52, 43, 76, 48, 91, 27, 60, 32, 87, 44, 93, 36, 49, 89, 86, 40, 94]\n",
      "[4, 12, 6, 21, 17, 4, 2, 3, 9, 13, 16, 12, 12, 13, 15, 9, 14, 16, 15, 21, 10, 19, 8, 15, 11, 13, 17, 9, 6, 11, 1, 15, 11, 10, 4, 4, 17, 6, 5, 3, 5, 4, 3, 10, 6, 6, 3, 1, 13, 18, 10, 10, 6, 5, 6, 10, 1, 1, 5, 1, 4, 6, 1, 1, 4, 5, 3, 5, 1]\n",
      "[ 74  45  80  66  29  92  30  55  83  59  78  62  46  82  54  63  58  72\n",
      "  75  79  68  88  71  85  73  57  51  38  47  31  61  77  56  41  34  69\n",
      "  50  33  26  90  35  53  81  39  37  42 101  70  65  67  64  52  43  76\n",
      "  48  91  27  60  32  87  44  93  36  49  89  86  40  94]\n",
      "[12  6 21 17  4  2  3  9 13 16 12 12 13 15  9 14 16 15 21 10 19  8 15 11\n",
      " 13 17  9  6 11  1 15 11 10  4  4 17  6  5  3  5  4  3 10  6  6  3  1 13\n",
      " 18 10 10  6  5  6 10  1  1  5  1  4  6  1  1  4  5  3  5  1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/bj/spr6xdy950jf8sj2svjhs0vh0000gn/T/ipykernel_8561/233018324.py:17: UserWarning: linestyle is redundantly defined by the 'linestyle' keyword argument and the fmt string \".b-\" (-> linestyle='-'). The keyword argument will take precedence.\n",
      "  plt.plot(x,y,'.b-',linestyle='None')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# need to add plot\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "\n",
    "age=list(age_frequency2.keys())\n",
    "frequency=list(age_frequency2.values())\n",
    "print(age)\n",
    "print(frequency)\n",
    "x=numpy.array(age[1:]) # not taking the \"None\" key by starting at position 1\n",
    "y=numpy.array(frequency[1:]) # not taking the \"None\" frequency by starting at position 1\n",
    "print(x)\n",
    "print(y)\n",
    "#fig,ax=plt.subplots()\n",
    "#ax.plot(x,y)\n",
    "#plt.scatter(x,y)\n",
    "plt.plot(x,y,'.b-',linestyle='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(figure generated by me)\n",
    "Notice that the peak has disappeared.  Probably there were some authors aged 43 who happened to have a large number of books in our collection.  Not counting those books multiple times elimited the artifact. Now the data looks more regular and follows a clear trend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with full text\n",
    "\n",
    "We now read in the .json files with full text that we have created by scraping the web previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4458\n"
     ]
    }
   ],
   "source": [
    "# letter_range was defined above when reading meta files\n",
    "adelaide_page_json = sc.textFile(\"./data/*page*\"+letter_range+\"*.json\")\n",
    "print(adelaide_page_json.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4458 elements in this RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(adelaide_page_json.first()) # at this point RDD consists of strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point the RDD consists of strings.  Let's examine the first string. It happens to be a string with a link followed by \"None\", indicating that in this particular case the data for the book was not successfully retrieved during the web scraping operation.   Other entries will contain the link followed by the full HTML page code for that particular book.  We want to filter out the \"None\" entries but for that we will have to convert the data from a simple string into something more useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"https://ebooks.adelaide.edu.au/m/maupassant/guy/accursed-bread/\", \"<!DOCTYPE html>\\n\\n<html xmlns=\\\"http://www.w3.org/1999/xhtml\\\">\\n<head>\\n<meta charset=\\\"utf-8\\\"/>\\n<title>The Accursed Bread / Guy de Maupassant</title><script type=\\\"application/ld+json\\\">\\n{\\n   \\\"@context\\\" : \\\"http://schema.org\\\",\\n   \\\"@type\\\" : \\\"Book\\\",\\n   \\\"author\\\" : \\\"Maupassant, Guy de, 1850-1893\\\",\\n   \\\"image\\\" : \\\"https://ebooks.adelaide.edu.au/m/maupassant/guy/accursed-bread/cover.jpg\\\",\\n   \\\"dateCreated\\\" : \\\"1883\\\",\\n   \\\"datePublished\\\" : \\\"2016-01-26\\\",\\n   \\\"description\\\" : \\\"The Accursed Bread : (Le Pain Maudit) / Guy de Maupassant\\\",\\n   \\\"inLanguage\\\" : \\\"en\\\",\\n   \\\"name\\\" : \\\"The Accursed Bread\\\",\\n   \\\"publisher\\\" : \\\"The University of Adelaide Library\\\",\\n   \\\"keywords\\\" : \\\"Literature\\\",\\n   \\\"url\\\" : \\\"https://ebooks.adelaide.edu.au/m/maupassant/guy/accursed-bread/\\\"\\n}\\n</script>\\n<!-- open graph -->\\n<meta content=\\\"The Accursed Bread\\\" property=\\\"og:title\\\"/>\\n<meta content=\\\"The Accursed Bread : (Le Pain Maudit) / Guy de Maupassant\\\" property=\\\"og:description\\\"/>\\n<meta content=\\\"https://ebooks.adelaide.edu.au/m/maupassant/guy/accursed-bread/\\\" property=\\\"og:url\\\"/>\\n<meta content=\\\"https://ebooks.adelaide.edu.au/m/maupassant/guy/accursed-bread/cover.jpg\\\" property=\\\"og:image\\\"/>\\n<!-- end meta -->\\n<link href=\\\"widgets/style.css\\\" rel=\\\"stylesheet\\\" type=\\\"text/css\\\"/><link href=\\\"/lib/widgets/not_epub.css\\\" rel=\\\"stylesheet\\\" type=\\\"text/css\\\"/>\\n<script type=\\\"text/javascript\\\">\\n\\n  var _gaq = _gaq || [];\\n  _gaq.push(['_setAccount', 'UA-4561916-1']);\\n  _gaq.push(['_trackPageview']);\\n\\n  (function() {\\n    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;\\n    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';\\n    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);\\n  })();\\n\\n</script>\\n<script type=\\\"text/javascript\\\">\\n//<![CDATA[\\nfunction getKey(event) {\\n    k = event.keyCode;\\n    if (k == 37) { var h=document.querySelector(\\\"link[rel=prev]\\\").getAttribute(\\\"href\\\"); window.location=h; }\\n    if (k == 39) { var h=document.querySelector(\\\"link[rel=next]\\\").getAttribute(\\\"href\\\"); window.location=h; }\\n}\\ndocument.onkeydown = getKey;\\n//]]>\\n</script>\\n<meta content=\\\"width=device-width\\\" name=\\\"viewport\\\"/>\\n<style type=\\\"text/css\\\">\\n/*<![CDATA[*/\\n@import url(\\\"//fonts.googleapis.com/css?family=Old+Standard+TT:italic,bold\\\");\\n.author {font-family:'Old Standard TT', Georgia, serif;font-style:italic;font-variant:normal;font-weight:normal;}\\n/*]]>*/\\n</style>\\n</head>\\n<body>\\n<div id=\\\"controls\\\">\\n<a class=\\\"closebtn\\\" href=\\\"#\\\" onclick=\\\"document.getElementById('controls').style.display = 'none';return false;\\\" title=\\\"Hide strip\\\">\\u2715</a>\\n<ul>\\n<li><a class=\\\"mdi mdi-information-outline\\\" href=\\\"/m/maupassant/guy/\\\" rel=\\\"author\\\" title=\\\"About this book\\\"> about</a></li>\\n<li><a class=\\\"mdi mdi-book-open\\\" href=\\\"/m/maupassant/guy/accursed-bread/\\\" title=\\\"read in browser\\\"> read</a></li>\\n<li><a class=\\\"mdi mdi-file\\\" href=\\\"/m/maupassant/guy/accursed-bread/complete.html\\\" title=\\\"the complete book in a single page\\\"> complete</a></li>\\n<li><a class=\\\"mdi mdi-download\\\" href=\\\"/cgi-bin/zip/m/maupassant/guy/accursed-bread\\\" title=\\\"Download a zip archive\\\"> download</a></li>\\n<li><a class=\\\"mdi mdi-cellphone-android\\\" href=\\\"/m/maupassant/guy/accursed-bread/accursed-bread.epub\\\" title=\\\"Download an ePub version\\\"> ePub</a></li>\\n<li><a class=\\\"mdi mdi-amazon\\\" href=\\\"/m/maupassant/guy/accursed-bread/accursed-bread.azw3\\\" title=\\\"Download a Kindle version\\\"> Kindle</a></li>\\n<li><span class=\\\"mdi mdi-share\\\"></span></li>\\n<li><a class=\\\"mdi mdi-facebook\\\" href=\\\"#\\\" onclick=\\\"window.open('https://www.facebook.com/sharer/sharer.php?u=https://ebooks.adelaide.edu.au/m/maupassant/guy/accursed-bread/complete.html','facebookShareDialog','width=626,height=436');return false;\\\" title=\\\"Share to Facebook\\\">\\u00a0</a></li>\\n<li><a class=\\\"mdi mdi-google-plus\\\" href=\\\"https://plus.google.com/share?url=https://ebooks.adelaide.edu.au/m/maupassant/guy/accursed-bread/complete.html\\\" onclick=\\\"javascript:window.open(this.href,'','menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;\\\" target=\\\"_blank\\\" title=\\\"Share to Google Plus\\\">\\u00a0</a></li>\\n<li><a class=\\\"mdi mdi-twitter\\\" href=\\\"http://twitter.com/share?text=https://ebooks.adelaide.edu.au/m/maupassant/guy/accursed-bread/complete.html\\\" onclick=\\\"javascript:window.open(this.href,'','menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;\\\" title=\\\"Share to Twitter\\\">\\u00a0</a></li>\\n</ul></div>\\n<div class=\\\"titlepage\\\" id=\\\"titlepage\\\">\\n<div style=\\\"border-bottom:2px solid #00609c;margin-bottom:3em;\\\">\\n<h2><span class=\\\"sc\\\">The Short Stories<br/>\\nof</span><br/>\\n<span class=\\\"author fs200 lh180\\\">Guy de Maupassant</span>\\n</h2>\\n</div>\\n<h1><span class=\\\"title fs150\\\">The Accursed Bread</span><br/>\\n<span class=\\\"sc\\\">(Le Pain Maudit)</span>\\n</h1>\\n<p class=\\\"imprint\\\">\\n</p>\\n</div>\\n<div class=\\\"titleverso\\\">\\n<p>First published in 1883.</p>\\n<p>This edition published by <a href=\\\"https://ebooks.adelaide.edu.au/\\\">eBooks@Adelaide</a>.</p>\\n<p>Last updated Tuesday, January 26, 2016 at 14:13.</p>\\n<div id=\\\"licence\\\">\\n<p>To the best of our knowledge, <strong>the text</strong> of this<br/>\\nwork is in the \\u201c<strong>Public Domain</strong>\\u201d in Australia.<br/>\\nHOWEVER, copyright law varies in other countries, and the work may\\nstill be under copyright in the country from which you are accessing this website.\\nIt is your responsibility to check the applicable copyright laws\\nin your country before downloading this work.</p>\\n</div>\\n<p>eBooks@Adelaide<br/>\\nThe University of Adelaide Library<br/>\\nUniversity of Adelaide<br/>\\nSouth Australia 5005</p>\\n</div>\\n<div class=\\\"chapter\\\" id=\\\"chapter1\\\">\\n<div class=\\\"header modern\\\">\\n<h3>The Accursed Bread</h3>\\n</div>\\n<p class=\\\"dropcap\\\">Daddy Taille had three daughters: Anna, the eldest, who was scarcely ever mentioned in the family; Rose, the second girl, who was eighteen; and Clara, the youngest, who was a girl of fifteen.</p>\\n<p>Old Taille was a widower, and a foreman in M. Lebrument\\u2019s button-manufactory. He was a very upright man, very well thought of, abstemious; in fact a sort of model workman. He lived at Havre, in the Rue d\\u2019Angoul\\u00eame.</p>\\n<p>When Anna ran away the old man flew into a fearful rage. He threatened to kill the seducer, who was head clerk in a large draper\\u2019s establishment in that town. Then, when he was told by various people that she was keeping very steady and investing money in Government securities, that she was no gadabout, but was kept by a Mons. Dubois, who was a judge of the Tribunal of Commerce, the father was appeased.</p>\\n<p>He even showed some anxiety as to how she was getting on, asked some of her old friends who had been to see her how she was getting on; and when told that she had her own furniture, and that her mantelpiece was covered with vases and the walls with pictures, that there were clocks and carpets everywhere, he gave a broad, contented smile. He had been working for thirty years to get together a wretched five or six thousand francs. This girl was evidently no fool.</p>\\n<p>One fine morning the son of Touchard, the cooper, at the other end of the street, came and asked him for the hand of Rose, the second girl. The old man\\u2019s heart began to beat, for the Touchards were rich and in a good position. He was decidedly lucky with his girls.</p>\\n<p>The marriage was agreed upon, and it was settled that it should be a grand affair, and the wedding dinner was to be held at Sainte\\u2013Adresse, at Mother Lusa\\u2019s restaurant. It would cost a lot certainly; but never mind, it did not matter just for once in a way.</p>\\n<p>But one morning, just as the old man was going home to breakfast with his two daughters the door opened suddenly, and Anna appeared. She was elegantly dressed, wore rings and an expensive bonnet, and looked undeniably pretty and nice. She threw her arms round her father\\u2019s neck before he could say a word, then fell into her sister\\u2019s arms with many tears, and then asked for a plate, so that she might share the family soup. Taille was moved to tears in his turn and said several times:</p>\\n<p>\\u201cThat is right, dear; that is right.\\u201d</p>\\n<p>Then she told them about herself. She did not wish Rose\\u2019s wedding to take place at Sainte\\u2013Adresse, \\u2014 certainly not. It should take place at her house, and would cost her father nothing. She had settled everything and arranged everything, so it was \\u201cno good to say any more about it, \\u2014 there!\\u201d</p>\\n<p>\\u201cVery well, my dear! very well!\\u201d the old man said, \\u201cwe will leave it so.\\u201d But then he felt some doubt. Would the Touchards consent? But Rose, the bride-elect, was surprised and asked, \\u201cWhy should they object, I should like to know? Just leave that to me, I will talk to Philip about it.\\u201d</p>\\n<p>She mentioned it to her lover the very same day, and he declared that it would suit him exactly. Father and Mother Touchard were naturally delighted at the idea of a good dinner which would cost them nothing, and said:</p>\\n<p>\\u201cYou may be quite sure that everything will be in first-rate style, as M. Dubois is made of money.\\u201d</p>\\n<p>They asked to be allowed to bring a friend, Mme. Florence, the cook on the first floor, and Anna agreed to everything.</p>\\n<p>The wedding was fixed for the last Tuesday of the month.</p>\\n<div class=\\\"section\\\" id=\\\"chapter2\\\">\\n<h4>2</h4>\\n<p>After the civil formalities and the religious ceremony the wedding party went to Anna\\u2019s house. Among those whom the Tailles had brought was a cousin of a certain age, a M. Sauvetanin, a man given to philosophical reflections, serious, and always very self-possessed, and Mme. Lamonoois, an old aunt.</p>\\n<p>M. Sauvetanin had been told off to give Anna his arm, as they were looked upon as the two most important persons in the company.</p>\\n<p>As soon as they had arrived at the door of Anna\\u2019s house she let go her companion\\u2019s arm, and ran on ahead, saying, \\u201cI will show you the way,\\u201d and ran upstairs while the invited guests followed more slowly; and, when they got upstairs, she stood on one side to let them pass, and they rolled their eyes and turned their heads in all directions to admire this mysterious and luxurious dwelling.</p>\\n<p>The table was laid in the drawing-room as the dining-room had been thought too small. Extra knives, forks, and spoons had been hired from a neighboring restaurant, and decanters full of wine under the rays of the sun which shown in through the window.</p>\\n<p>The ladies went into the bedroom to take off their shawls and bonnets, and Father Touchard, who was standing at the door, squinted at the low wide bed, and made funny and suggestive signs to the men, with many a wink and a nod. Daddy Taille, who thought a great deal of himself, looked with fatherly pride at his child\\u2019s well-furnished rooms, and went from one to the other holding his hat in his hand, making a mental inventory of everything, and walking like a verger in a church.</p>\\n<p>Anna went backwards and forwards, ran about giving orders and hurrying on the wedding feast. Soon she appeared at the door of the dining-room, and cried: \\u201cCome here, all of you, for a moment,\\u201d and when the twelve guests did as they were asked they saw twelve glasses of Madeira on a small table.</p>\\n<p>Rose and her husband had their arms round each other\\u2019s waists, and were kissing each other in every corner. Mons. Sauvetanin never took his eyes off Anna; he no doubt felt that ardor, that sort of expectation which all men, even if they are old and ugly, feel for women of a certain stamp, as if they owed a little of themselves, professionally, to all males.</p>\\n<p>They sat down, and the wedding-breakfast began; the relations sitting at one end of the table and the young people at the other. Mme. Touchard, the mother, presided on the right and the bride on the left. Anna looked after everybody, saw that the glasses were kept filled and the plates well supplied. The guests evidently felt a certain respectful embarrassment at the sight of all the sumptuousness of the rooms and at the lavish manner in which they were treated. They all ate heartily of the good things provided, but there were no jokes such as are prevalent at weddings of that sort; it was all too grand, and it made them feel uncomfortable. Old Madame Touchard, who was fond of a bit of fun, tried to enliven matters a little, and at the beginning of the dessert she exclaimed: \\u201cI say, Philip, do sing us something.\\u201d The neighbors in their street considered that he had the finest voice in all Havre.</p>\\n<p>The bridegroom got up, smiled, and turning to his sister-inlaw, from politeness and gallantry, tried to think of something suitable for the occasion, something serious and correct, to harmonize with the seriousness of the repast.</p>\\n<p>Anna had a satisfied look on her face, and leaned back in her chair to listen, and all assumed looks of attention, though prepared to smile should smiles be called for.</p>\\n<p>The singer announced, \\u201cThe Accursed Bread,\\u201d and extending his right arm, which made his coat ruck up into his neck, he began.</p>\\n<p>It was decidedly long, three verses of eight lines each, with the last line and the last line but one repeated twice.</p>\\n<p>All went well for the first two verses; they were the usual commonplaces about bread gained by honest labor and by dishonesty. The aunt and the bride wept outright. The cook, who was present, at the end of the first verse looked at a roll which she held in her hand with running eyes, as if they applied to her, while all applauded vigorously. At the end of the second verse the two servants, who were standing with their backs to the wall, joined loudly in the chorus, and the aunt and the bride wept outright. Daddy Taille blew his nose with the noise of a trombone, and old Touchard brandished a whole loaf half over the table, and the cook shed silent tears on the crust which she was still holding.</p>\\n<p>Amidst the general emotion M. Sauvetanin said:</p>\\n<p>\\u201cThat is the right sort of song; very different to the nasty, risky things one generally hears at weddings.\\u201d</p>\\n<p>Anna, who was visibly affected, kissed her hand to her sister, and pointed to her husband with an affectionate nod, as if to congratulate her.</p>\\n<p>Intoxicated by his success, the young man continued, and unfortunately the last verse contained the words about the bread of dishonor gained by young girls who had been led astray from the paths of virtue. No one took up the refrain about this bread, supposed to be eaten with tears, except old Touchard and the two servants. Anna had grown deadly pale, and cast down her eyes, while the bridegroom looked from one to the other without understanding the reason for this sudden coldness, and the cook hastily dropped the crust as if it were poisoned.</p>\\n<p>Mons. Sauvetanin said solemnly, in order to save the situation: \\u201cThat last couplet is not at all necessary;\\u201d and Daddy Taille, who had got red up to the ears, looked round the table fiercely.</p>\\n<p>Then Anna, with her eyes swimming in tears, told the servants, in the faltering voice of a woman trying to stifle her sobs, to bring the champagne.</p>\\n<p>All the guests were suddenly seized with exuberant joy, and all their faces became radiant again. And when old Touchard, who had seen, felt, and understood nothing of what was going on, and, pointing to the guests so as to emphasize his words, sang the last words of the refrain:</p>\\n<p>\\u201cChildren, I warn you all to eat not of that bread,\\u201d the whole company, when they saw the champagne bottles, with their necks covered with gold foil appear, burst out singing, as if electrified by the sight:</p>\\n<p>\\u201cChildren, I warn you all to eat not of that bread.\\u201d</p>\\n</div>\\n</div>\\n<div class=\\\"colophon\\\">\\n<p>This web edition published by:</p>\\n<p>eBooks@Adelaide<br/>\\nThe University of Adelaide Library<br/>\\nUniversity of Adelaide<br/>\\nSouth Australia 5005</p>\\n</div>\\n</body>\\n</html>\\n\"]\n"
     ]
    }
   ],
   "source": [
    "print(adelaide_page_json.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We must now convert these strings into Python objects that we can manipulate further. We can use the json module for this.\n",
    "\n",
    "The entry consists of a list with two elements: the url of a page followed by the HTML content of the page.  We should get rid of entries containing \"None\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "adelaide_page = adelaide_page_json.map(json.loads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examine the type of data in this new RDD and see that it consists of lists, each with two items in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "#print(adelaide_page.first())\n",
    "print(type(adelaide_page.first()))\n",
    "# now RDD of lists, each containing two strings\n",
    "print(len(adelaide_page.first()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we filter out the \"None\" entries i.e. those which have \"None\" at index 1 in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adelaide_page = adelaide_page.filter(lambda rec: rec[1] != \"None\")\n",
    "print(adelaide_page.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The count call shows how many elements remain. After the filtering, we can look at the first of the remaining valid elements, showing the html code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ebooks.adelaide.edu.au/m/maupassant/guy/accursed-bread/\n",
      "--------------\n",
      "<class 'str'>\n",
      "--------------\n",
      "<!DOCTYPE html>\n",
      "\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<title>The Accursed Bread / Guy de Maupassant</title><script type=\"application/ld+json\">\n",
      "{\n",
      "   \"@context\" : \"http://schema.org\",\n",
      "   \"@type\" : \"Book\",\n",
      "   \"author\" : \"Maupassant, Guy de, 1850-1893\",\n",
      "   \"image\" : \"https://ebooks.adelaide.edu.au/m/maupassant/guy/accursed-bread/cover.jpg\",\n",
      "   \"dateCreated\" : \"1883\",\n",
      "   \"datePublished\" : \"2016-01-26\",\n",
      "   \"description\" : \"The Accursed Bread : (Le Pain Maudit) / G\n"
     ]
    }
   ],
   "source": [
    "book=adelaide_page.first()\n",
    "print(book[0])\n",
    "print(\"--------------\")\n",
    "print(type(book[1])) # string containing HTML code for book\n",
    "print(\"--------------\")\n",
    "print(book[1][0:500]) # print only first 500 characters for brevity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that some books are present multiple times in our dataset.  But we want to have each book present only once.\n",
    "\n",
    "If the RDD consists of key,value pairs, for example:\n",
    "\n",
    "(a,1) (a,2) (b,1) (c,1) (c,2)\n",
    "\n",
    "then the groupByKey method of the RDD will return a new RDD consisting of\n",
    "\n",
    "(a, [1,2]) (b,[1,]) (c,[1,2])\n",
    "\n",
    "i.e. it will consist of keys followed by a list of values in the original RDD associated with that key.\n",
    "\n",
    "In our case we apply the groupByKey operation, then convert the values of the resulting RDD into a list (using the Python list function), and then keep only one element of that list, using the itemgetter[0] Python function which, when applied to a list, returns its first element (with index 0).\n",
    "\n",
    "In this way, if the book with a specific URL key was present multiple times in our RDD, we keep the value with one occurence of the key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 87:=============================================>         (54 + 11) / 66]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "adelaide_page_unique = adelaide_page.groupByKey()\\\n",
    "                                    .mapValues(list)\\\n",
    "                                    .mapValues(itemgetter(0))\n",
    "print(adelaide_page_unique.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that indeed there were books showing up multiple times in our RDD, since after this operation the number of elements in our RDD is further reduced.\n",
    "\n",
    "At this point the values in our RDD store a sting of raw HTML code of the page for the book. We then want to filter out everything except the actual text of the book which we will want to analyze further.  We do that by working with Beautiful Soup and eliminating unnecessary tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "https://ebooks.adelaide.edu.au/m/meredith/george/adventures-of-harry-richmond/\n",
      "<!DOCTYPE html>\n",
      "\n",
      "<html xmlns=\"http://www.w3.org/1999/xhtml\">\n",
      "<head>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<title>The Adventures of Harry Richmond / George Meredith</title><script type=\"application/ld+json\">\n",
      "{\n",
      "   \"@context\" : \"http://schema.org\",\n",
      "   \"@type\" : \"Book\",\n",
      "   \"author\" : \"Meredith, George, 1828-1909\",\n",
      "   \"image\" : \"https://ebooks.adelaide.edu.au/m/meredith/george/adventures-of-harry-richmond/cover.jpg\",\n",
      "   \"dateCreated\" : \"1871\",\n",
      "   \"datePublished\" : \"2016-01-11\",\n",
      "   \"description\" : \"The Adventures o\n"
     ]
    }
   ],
   "source": [
    "book=adelaide_page_unique.first()\n",
    "print(type(book))\n",
    "print(book[0])\n",
    "print(book[1][0:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to clean up the text by removing a series of tags.  We can use the extract method of BeautifulSoup object. We also use the chain method to define a series of findAll operations in an iterable which we can then loop over."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "from operator import itemgetter\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_text(page):\n",
    "    if page:\n",
    "        soup = BeautifulSoup(page, 'html.parser')\n",
    "        it = chain(soup.findAll(['meta', 'script', 'head']),\n",
    "                   soup.findAll('div', {\"id\" : \"controls\"}),\n",
    "                   soup.findAll('div', {\"class\" : \"contents\"}),\n",
    "                   soup.findAll('div', {\"class\" : \"titleverso\"}),\n",
    "                   soup.findAll('div', {\"class\" : \"colophon\"}),\n",
    "                   soup.findAll('span', {\"class\" : \"author\"}))\n",
    "        for div in it:\n",
    "            div.extract()\n",
    "        return soup.get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "adelaide_text = adelaide_page_unique.mapValues(extract_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have an RDD which contains the pure text of the book without any HTML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tuple'>\n",
      "https://ebooks.adelaide.edu.au/m/meredith/george/adventures-of-harry-richmond/\n",
      "The Adventures\n",
      "of\n",
      "Harry Richmond\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Table of Contents\n",
      "\n",
      "\n",
      "I am a Subject of Contention\n",
      "\n",
      "An Adventure on my own Account\n",
      "\n",
      "Dipwell Farm\n",
      "\n",
      "I have a Taste of Grandeur\n",
      "\n",
      "I make a Dear Friend\n",
      "\n",
      "A Tale of a Goose\n",
      "\n",
      "A Free Life on the Road\n",
      "\n",
      "Janet Ilchester\n",
      "\n",
      "An Evening with Captain Bulsted\n",
      "\n",
      "An Expedition\n",
      "\n",
      "The great Fog and the Fire at Midnight\n",
      "\n",
      "We find ourselves Bound on a Voyage\n",
      "\n",
      "We Conduct several Learned Arguments with the Captain of the Priscilla\n",
      "\n",
      "I Meet old Friends\n",
      "\n",
      "We are Accosted by a Beautiful little Lady in the Forest\n",
      "\n",
      "The Statue on the Promontory\n",
      "\n",
      "My Father Breathes, Moves, and Speaks\n",
      "\n",
      "We Pas\n"
     ]
    }
   ],
   "source": [
    "book_text=adelaide_text.first()\n",
    "print(type(book_text))\n",
    "print(book_text[0])\n",
    "print(book_text[1][0:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have a large dataset that will be a bit unwieldy to work with if we want our operations to be completed in a reasonable amount of time.\n",
    "\n",
    "To make thinks a bit easier, we will restrict our analysis to books written in the modern era, in this case defined as between 1900 and 1938. We can easily identify these books using our meta RDD we created previously, and applying a filter on the value of dateCreated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "modern_era_books = adelaide_meta_val.filter(lambda rec: 1900 < rec.get('dateCreated', 0) < 1938)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to filter out all books not in English. Again we use the metadata RDD, which we filter further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "modern_era_en_books = modern_era_books.filter(lambda rec: rec.get('inLanguage', '') == 'en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "398"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modern_era_en_books.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meta information about each book and the book's text are stored in two separate RDDs.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modern_era_books.map(lambda rec: rec['author']).distinct().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The meta information about each book and the book's text are each stored in two separate RDDs. In order to retrieve the texts written during the modernism era, we will need to join the RDD of modern book era meta information and the RDD of books' text.  The join operation takes two key-value RDDs and produces a new RDD consisting of those values in the original RDDs which share identical keys.  \n",
    "\n",
    "First we need to take our meta RDD and convert it into a key,value RDD, with the url value serving as key.  We can do this through the keyBy operations, which adds a key produced by a function given as its argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('https://ebooks.adelaide.edu.au/l/literature/english-men-of-letters/andrew-marvell/', {'@type': 'Book', '@context': 'http://schema.org', 'collections': ['Biography'], 'url': 'https://ebooks.adelaide.edu.au/l/literature/english-men-of-letters/andrew-marvell/', 'dateCreated': 1905, 'datePublished': '2015-10-20', 'author': 'Birrell, Augustine, 1850-1933', 'image': 'https://ebooks.adelaide.edu.au/l/literature/english-men-of-letters/andrew-marvell/cover.jpg', 'name': 'Andrew Marvell', 'publisher': 'The University of Adelaide Library', 'description': 'Andrew Marvell / Augustine Birrell', 'inLanguage': 'en', 'author_lastname': 'Birrell', 'author_firstname': 'Augustine', 'author_birth': 1850, 'author_death': 1933})\n"
     ]
    }
   ],
   "source": [
    "# need to append complete.html to get matching URL\n",
    "modern_era_books_kv = modern_era_books.keyBy(lambda rec: rec['url'])\n",
    "print(modern_era_books_kv.first())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now when we perform a join operation, two RDDs will be joined, and for (key, value1) and (key, value2) data items in original datasets which share the same key, the new dataset will have (key, (value1,value2)) data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "modernism_meta_text = modern_era_books_kv.join(adelaide_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examine the structure of the resulting data by printing out the types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 102:==================================================>    (85 + 7) / 92]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397\n",
      "<class 'tuple'>\n",
      "2\n",
      "<class 'str'>\n",
      "<class 'dict'>\n",
      "<class 'str'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "print(modernism_meta_text.count())\n",
    "book=modernism_meta_text.first()\n",
    "print(type(book))\n",
    "print(len(book))\n",
    "print(type(book[0]))\n",
    "print(type(book[1][0]))\n",
    "print(type(book[1][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/\n",
      "-----\n",
      "{'publisher': 'The University of Adelaide Library', '@type': 'Book', '@context': 'http://schema.org', 'url': 'https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'dateCreated': 1913, 'datePublished': '2006-10-15', 'author': 'Hardy, Thomas, 1840-1928', 'name': 'A Changed Man', 'dateModified': '2014-03-07', 'keywords': 'Literature', 'image': 'https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/cover.jpg', 'description': 'A Changed Man / Thomas Hardy', 'inLanguage': 'en', 'author_lastname': 'Hardy', 'author_firstname': 'Thomas', 'author_birth': 1840, 'author_death': 1928}\n",
      "-----\n",
      "A Changed Man\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Prefatory Note\n",
      "\n",
      "I reprint in this volume, for what they may be worth, a dozen minor novels that have been published in the\n",
      "periodical press at various dates in the past, in order to render them accessible to readers who desire to have them in\n",
      "the complete series issued by my publishers. For aid in reclaiming some of the narratives I express my thanks to the\n",
      "proprietors and editors of the newspapers and magazines in whose pages they first appeared.\n",
      "T. H. August 1913.\n",
      "\n",
      "\n",
      "\n",
      "A Changed Man\n",
      "\n",
      "\n",
      "Chapter I\n",
      "The person who, next to the actors themselves, chanced to know most of thei\n"
     ]
    }
   ],
   "source": [
    "print(book[0])\n",
    "print(\"-----\")\n",
    "print(book[1][0])\n",
    "print(\"-----\")\n",
    "print(book[1][1][0:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we don't actually need the metadata at this point, only the text. In the joined RDD the text is at position 1 in value.  We extract it into a new RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/\n",
      "A Changed Man\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Prefatory Note\n",
      "\n",
      "I reprint in this volume, for what they may be worth, a dozen minor novels that have been published in the\n",
      "periodical press at various dates in the past, in order to render them accessible to readers who desire to have them in\n",
      "the complete series issued by my publishers. For aid in reclaiming some of the narratives I express my thanks to the\n",
      "proprietors and editors of the newspapers and magazines in whose pages they first appeared.\n",
      "T. H. August 1913.\n",
      "\n",
      "\n",
      "\n",
      "A Changed Man\n",
      "\n",
      "\n",
      "Chapter I\n",
      "The person who, next to the actors themselves, chanced to know most of thei\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "modernism_text = modernism_meta_text.mapValues(lambda x: x[1])\n",
    "aa=modernism_text.first()\n",
    "#modernism_word = modernism_text.flatMapValues(string.split)\n",
    "print(aa[0])\n",
    "print(aa[1][0:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have what we need: an RDD with the full text of books from a certain period, filtered by desired criteria.  Now we want to do some analysis on their contents.  First, we want to look at the words used and their frequency, i.e. we need to count how many times each word is used, and then make a sorted list which will have words sorted by their frequency.\n",
    "\n",
    "To do this, we have to split our documents into individual words.  To do that, we define a split function that uses a standard split() Python method for strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(s):\n",
    "    return s.split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply it to the full text RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "modernism_word = modernism_text.flatMapValues(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting output consists of tuples, each holding the url as identifier and a string containing the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'A'),\n",
       " ('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'Changed'),\n",
       " ('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'Man'),\n",
       " ('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'Prefatory'),\n",
       " ('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'Note'),\n",
       " ('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'I'),\n",
       " ('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'reprint'),\n",
       " ('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'in'),\n",
       " ('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'this'),\n",
       " ('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'volume,')]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modernism_word.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to remove the common, non-interesting words, so called stopwords.  The selection of these is somewhat arbitrary, and depends on the problem you are interested in.  We also have to remove punctuations so we define a function with a regular expression to do that. Again, regular expressions are not covered in this course in any detail, but they are extremely useful when manipulating text and you can learn more about them online."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation\n",
    "def remove_punctuations(word):\n",
    "    return re.sub(r'[{}‘—’”“]'.format(punctuation), \" \", word).strip()\n",
    "\n",
    "stopwords  = set(['all', 'pointing', 'four', 'go', 'oldest', 'seemed', 'whose', 'certainly',\n",
    "'young',  'presents', 'to', 'asking', 'those', 'under', 'far', 'every',\n",
    "'presented', 'did',  'turns', 'large', 'p', 'small', 'parted', 'smaller',\n",
    "'says', 'second', 'further',  'even', 'what', 'anywhere', 'above', 'new',\n",
    "'ever', 'full', 'men', 'here', 'youngest',  'let', 'groups', 'others', 'alone',\n",
    "'along', 'great', 'k', 'put', 'everybody', 'use',  'from', 'working', 'two',\n",
    "'next', 'almost', 'therefore', 'taken', 'until', 'today',  'more', 'knows',\n",
    "'clearly', 'becomes', 'it', 'downing', 'everywhere', 'known', 'cases',  'must',\n",
    "'me', 'states', 'room', 'f', 'this', 'work', 'itself', 'can', 'mr', 'making',\n",
    "'my', 'numbers', 'give', 'high', 'something', 'want', 'needs', 'end', 'turn',\n",
    "'rather', 'how', 'y', 'may', 'after', 'such', 'man', 'a', 'q', 'so', 'keeps',\n",
    "'order', 'furthering',  'over', 'years', 'ended', 'through', 'still', 'its',\n",
    "'before', 'group', 'somewhere',  'interesting', 'better', 'differently',\n",
    "'might', 'then', 'non', 'good', 'somebody',  'greater', 'downs', 'they', 'not',\n",
    "'now', 'gets', 'always', 'l', 'each', 'went', 'side',  'everyone', 'year',\n",
    "'our', 'out', 'opened', 'since', 'got', 'shows', 'turning', 'differ',  'quite',\n",
    "'members', 'ask', 'wanted', 'g', 'could', 'needing', 'keep', 'thing', 'place',\n",
    "'w', 'think', 'first', 'already', 'seeming', 'number', 'one', 'done',\n",
    "'another', 'open',  'given', 'needed', 'ordering', 'least', 'anyone', 'their',\n",
    "'too', 'gives', 'interests',  'mostly', 'behind', 'nobody', 'took', 'part',\n",
    "'herself', 'than', 'kind', 'b', 'showed',  'older', 'likely', 'r', 'were',\n",
    "'toward', 'and', 'sees', 'turned', 'few', 'say', 'have',  'need', 'seem',\n",
    "'saw', 'orders', 'that', 'also', 'take', 'which', 'wanting', 'sure', 'shall',\n",
    "'knew', 'wells', 'most', 'nothing', 'why', 'parting', 'noone', 'later', 'm',\n",
    "'mrs', 'points', 'fact', 'show', 'ending', 'find', 'state', 'should', 'only',\n",
    "'going', 'pointed', 'do', 'his', 'get', 'cannot', 'longest', 'during', 'him',\n",
    "'areas', 'h', 'she', 'x', 'where', 'we', 'see', 'are', 'best', 'said', 'ways',\n",
    "'away', 'enough', 'smallest',  'between', 'across', 'ends', 'never', 'opening',\n",
    "'however', 'come', 'both', 'c', 'last',  'many', 'against', 's', 'became',\n",
    "'faces', 'whole', 'asked', 'among', 'point', 'seems',  'furthered', 'furthers',\n",
    "'puts', 'three', 'been', 'much', 'interest', 'wants', 'worked',  'an',\n",
    "'present', 'case', 'myself', 'these', 'n', 'will', 'while', 'would', 'backing',\n",
    "'is', 'thus', 'them', 'someone', 'in', 'if', 'different', 'perhaps', 'things',\n",
    "'make',  'same', 'any', 'member', 'parts', 'several', 'higher', 'used', 'upon',\n",
    "'uses', 'thoughts',  'off', 'largely', 'i', 'well', 'anybody', 'finds',\n",
    "'thought', 'without', 'greatest',  'very', 'the', 'yours', 'latest', 'newest',\n",
    "'just', 'less', 'being', 'when', 'rooms',  'facts', 'yet', 'had', 'lets',\n",
    "'interested', 'has', 'gave', 'around', 'big', 'showing',  'possible', 'early',\n",
    "'know', 'like', 'necessary', 'd', 't', 'fully', 'become', 'works',  'grouping',\n",
    "'because', 'old', 'often', 'some', 'back', 'thinks', 'for', 'though', 'per',\n",
    "'everything', 'does', 'either', 'be', 'who', 'seconds', 'nowhere', 'although',\n",
    "'by', 'on',  'about', 'goods', 'asks', 'anything', 'of', 'o', 'or', 'into',\n",
    "'within', 'down', 'beings',  'right', 'your', 'her', 'area', 'downed', 'there',\n",
    "'long', 'way', 'was', 'opens', 'himself',  'but', 'newer', 'highest', 'with',\n",
    "'he', 'made', 'places', 'whether', 'j', 'up', 'us',  'problem', 'z', 'clear',\n",
    "'v', 'ordered', 'certain', 'general', 'as', 'at', 'face', 'again',  'no',\n",
    "'generally', 'backs', 'grouped', 'other', 'you', 'really', 'felt', 'problems',\n",
    "'important', 'sides', 'began', 'younger', 'e', 'longer', 'came', 'backed',\n",
    "'together',  'u', 'presenting', 'evenly', 'having', 'once'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now apply a series of filters.  First we make all words lower case, then we apply our functions to remove punctuations, split string again in case there are white spaces after punctuation removal, then remove stopwords, then only keep words longer than 3 characters.  The inal isalpha filter removes all words which contain nonalphabetic characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "modernism_word_filt = modernism_word.mapValues(lambda x: x.lower())\\\n",
    "                                    .mapValues(remove_punctuations)\\\n",
    "                                    .flatMapValues(lambda x: x.split())\\\n",
    "                                    .filter(lambda pair: pair[1] not in stopwords)\\\n",
    "                                    .filter(lambda pair: len(pair[1]) > 3)\\\n",
    "                                    .filter(lambda pair: pair[1].isalpha())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a cleaned up dataset which should consist of just the valid words we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'changed'),\n",
       " ('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'prefatory'),\n",
       " ('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'note'),\n",
       " ('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'reprint'),\n",
       " ('https://ebooks.adelaide.edu.au/h/hardy/thomas/changed/', 'volume')]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modernism_word_filt.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we count the words.  At this point we just want the word frequency across all books and so don't need the URL identifiers.  Thus we take only the values, map them to the (x,1) key-value pair, and apply reduceByKey to that.  Now each word functions as a key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import add\n",
    "modernism_word_count = modernism_word_filt.values().map(lambda x: (x, 1)).reduceByKey(add)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now modernism_word_count has the word frequency, but they are not ordered.  To see the words occurring most often, we can use the top() method.  This takes as arguments the number of top words we want to see and the value by which we order them, here just the frequency of each word which is in element 1 of the tuple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully, through these examples you have gained an appreciation of Spark.  We will continue with some additional, more advanced features in the next lesson.  Compared to what we have done in previous lessons, Spark might look rather simple.  However, that is its point.  The code written here that you might be running on your desktop would run equally well on a large Spark cluster storing terabytes of data.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
